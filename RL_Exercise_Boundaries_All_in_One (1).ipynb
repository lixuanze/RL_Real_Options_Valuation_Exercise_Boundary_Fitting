{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Reinforcement Learning Solver for Pricing Simple Bermudan Put Options for only *1* Intermediate Decision Points**"
      ],
      "metadata": {
        "id": "XpqB2a_tYIOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install QuantLib\n",
        "!pip install -q tf-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98j4oe6sZhAZ",
        "outputId": "f5b9585b-7fae-41a5-ad06-abc2629691fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: QuantLib in /usr/local/lib/python3.7/dist-packages (1.26)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf-agents in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.21.6)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (0.5.0)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (0.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-probability>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from tf-agents) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (4.2.0)\n",
            "Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (2.1.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (3.17.3)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<=0.23.0,>=0.17.0->tf-agents) (0.16.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.16.0->tf-agents) (0.1.7)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.16.0->tf-agents) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.16.0->tf-agents) (0.5.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analytical Solutions - Binomial Tree Option Pricing Method**"
      ],
      "metadata": {
        "id": "qrBMV18BZubN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import QuantLib as ql \n",
        "import pandas as pd\n",
        "def get_simple_bermudan_option(): \n",
        "    maturity = ql.Date(31, 12, 2022)\n",
        "    S0=5\n",
        "    K = 5\n",
        "    r = 0.03\n",
        "    sigma = 0.10\n",
        "    d = 0.0\n",
        "    otype = ql.Option.Put\n",
        "    dc = ql.Actual365Fixed()\n",
        "    calendar = ql.NullCalendar()\n",
        "\n",
        "    today = ql.Date(1, 1, 2021)\n",
        "    bermudan = ql.Date(1,1,2022)\n",
        "    ql.Settings.instance().evaluationDate = today\n",
        "\n",
        "    payoff = ql.PlainVanillaPayoff(otype, K)\n",
        "\n",
        "    bermudan_exercise = ql.BermudanExercise([today, bermudan, maturity])\n",
        "    bermudan_option=ql.VanillaOption(payoff, bermudan_exercise)\n",
        "\n",
        "    american_exercise = ql.AmericanExercise(today, maturity)\n",
        "    american_option = ql.VanillaOption(payoff, american_exercise)\n",
        "\n",
        "    d_ts = ql.YieldTermStructureHandle(ql.FlatForward(today, d, dc))\n",
        "    r_ts = ql.YieldTermStructureHandle(ql.FlatForward(today, r, dc))\n",
        "    sigma_ts = ql.BlackVolTermStructureHandle(ql.BlackConstantVol(today, calendar, sigma, dc))\n",
        "    bsm_process = ql.BlackScholesMertonProcess(ql.QuoteHandle(ql.SimpleQuote(S0)), d_ts, r_ts, sigma_ts)\n",
        "\n",
        "    binomial_engine = ql.BinomialVanillaEngine(bsm_process, \"crr\", 100)\n",
        "    bermudan_option.setPricingEngine(binomial_engine)\n",
        "    return bermudan_option.NPV()"
      ],
      "metadata": {
        "id": "lpEWUgiOZt2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pricing_dict = {}\n",
        "pricing_dict['Simple Bermudan - Binomial Tree'] = get_simple_bermudan_option()\n",
        "pricing_df = pd.DataFrame.from_dict(pricing_dict, orient='index')\n",
        "pricing_df.columns = ['Option Price']\n",
        "print(pricing_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97Hpk86DZp4Z",
        "outputId": "71927f0e-4480-46ff-e41f-a2967ae27f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 Option Price\n",
            "Simple Bermudan - Binomial Tree       0.16845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Reinforcement Learning Solver to Solve Simple Bermudan Put Option Prices**"
      ],
      "metadata": {
        "id": "injAyCSJdVPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deep-Q Network**"
      ],
      "metadata": {
        "id": "uSXDcqBJ-mfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tf-agents\n",
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "i2ONsJxzd9kR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471de83a-9b5e-4b97-ae0d-9c3d5143f6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.17.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 25.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tf_agents.policies import policy_saver\n",
        "import tempfile\n",
        "import random\n",
        "import os\n",
        "from tf_agents.utils import common  # loss function\n",
        "from tf_agents.trajectories import trajectory  # s->s' trajectory\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer  # replay buffer\n",
        "from tf_agents.networks import q_network  # Q net\n",
        "from tf_agents.environments import tf_py_environment  # gym to tf gym\n",
        "from tf_agents.environments import gym_wrapper  # wrap OpenAI gym\n",
        "from tf_agents.agents.dqn import dqn_agent  # DQN Agent\n",
        "from tf_agents.agents.ppo import ppo_agent #PPO agent\n",
        "from tf_agents.networks.actor_distribution_network import ActorDistributionNetwork\n",
        "from tf_agents.networks.value_network import ValueNetwork\n",
        "from tensorflow.keras.activations import gelu\n",
        "from tensorflow_addons.optimizers import Yogi\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gym\n",
        "import QuantLib as ql  # used for calculating the price of option if we hold it, baseline\n",
        "\n",
        "# Bermudan Put Gym Environment\n",
        "class BermudanOptionEnv(gym.Env): #Bermudan Put\n",
        "    def __init__(self):\n",
        "        self.S0 = 5.0\n",
        "        self.K = 5.0\n",
        "        self.r = 0.03\n",
        "        self.sigma = 0.10\n",
        "        self.T = 2.0\n",
        "        self.N = 730    # 500 days\n",
        "        self.S1 = 0\n",
        "        self.reward = 0\n",
        "        self.current_day = 0    # from day 0 taking N steps to day N\n",
        "\n",
        "        self.action_space = gym.spaces.Discrete(2)         # 0: hold, 1:exercise, the action space, the RL should learn it\n",
        "        self.observation_space = gym.spaces.Box(low=np.array([0, 0]), high=np.array(\n",
        "            [np.inf, 1.0]), dtype=np.float32)      # S in [0, inf], tao in [0, 1]\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 1:        # we exercise the option\n",
        "            reward = max(self.K-self.S1, 0.0) * np.exp(-self.r * self.T * (self.current_day/self.N)) #early payoff\n",
        "            done = True\n",
        "        else:       # we hold the option, wait to the next exercise date\n",
        "            if self.current_day == self.N:    # at maturity\n",
        "                reward = max(self.K-self.S1, 0.0) * np.exp(-self.r * self.T) # payoff after discouted\n",
        "                done = True\n",
        "            else:  # move to the next exercise date\n",
        "                reward = 0 # no payoff\n",
        "                # lnS1 - lnS0 = (r - 1/2*sigma^2)*t + sigma * Wt: GBM stock path solution.\n",
        "                self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.current_day/self.N) + self.sigma * np.sqrt(self.current_day/self.N) * np.random.normal()) #GBM process price\n",
        "                self.current_day += 365\n",
        "                done = False # move to next time\n",
        "\n",
        "        tao = 1.0 - self.current_day/self.N       # time to maturity, in unit of fraction of total_length\n",
        "        return np.array([self.S1, tao]), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_day = 0\n",
        "        self.S1 = self.S0\n",
        "        tao = 1.0 - self.current_day/self.N     # time to maturity, in unit of fraction of total_length\n",
        "        return [self.S1, tao]"
      ],
      "metadata": {
        "id": "GCA9sUWBeBKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# monte-carlo simulation of stock prices\n",
        "prices = []\n",
        "S1 = 5\n",
        "r = 0.03\n",
        "sigma = 0.10\n",
        "N = 730\n",
        "T = 2.0\n",
        "current_day = 0\n",
        "for j in range(10):\n",
        "  for i in range(N):\n",
        "    prices.append(S1)\n",
        "    S1 = S1 * np.exp((r - 0.5 * sigma**2) * (T/N) + sigma * np.sqrt(T/N) * np.random.normal()) #GBM process price\n",
        "  plt.plot(prices)\n",
        "  prices = []\n",
        "  S1 = 5\n",
        "  # current_day += 365\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('Underlying Stock Prices')\n",
        "plt.title(\"GBM Processes - 10 sample paths\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "KZFY7-3GmX6Y",
        "outputId": "6a2b3d0e-f9eb-4f11-a7a6-ed618a48a4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'GBM Processes - 10 sample paths')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deep Q Network**"
      ],
      "metadata": {
        "id": "wKwQgSXnhjh1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HsRJyhBJYEV0",
        "outputId": "ec2d3f75-b8cb-4ff5-868f-aa99e37aac8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.foldr(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
            "step = 200: loss = 0.006929691880941391\n",
            "step = 400: loss = 0.010454745963215828\n",
            "step = 600: loss = 0.008971500210464\n",
            "step = 800: loss = 0.007425240240991116\n",
            "step = 1000: loss = 0.008744623512029648\n",
            "step = 1000: Average Return = 0.08278129994869232\n",
            "step = 1200: loss = 0.009004545398056507\n",
            "step = 1400: loss = 0.010528857819736004\n",
            "step = 1600: loss = 0.0061349933966994286\n",
            "step = 1800: loss = 0.0065862336196005344\n",
            "step = 2000: loss = 0.006593839731067419\n",
            "step = 2000: Average Return = 0.2215465009212494\n",
            "step = 2200: loss = 0.0035015123430639505\n",
            "step = 2400: loss = 0.004733758512884378\n",
            "step = 2600: loss = 0.003541000420227647\n",
            "step = 2800: loss = 0.005625464022159576\n",
            "step = 3000: loss = 0.0058705247938632965\n",
            "step = 3000: Average Return = 0.02982417307794094\n",
            "step = 3200: loss = 0.005895243491977453\n",
            "step = 3400: loss = 0.006506139412522316\n",
            "step = 3600: loss = 0.002800279762595892\n",
            "step = 3800: loss = 0.004861291032284498\n",
            "step = 4000: loss = 0.0037330910563468933\n",
            "step = 4000: Average Return = 0.1044318675994873\n",
            "step = 4200: loss = 0.005013365298509598\n",
            "step = 4400: loss = 0.006688621360808611\n",
            "step = 4600: loss = 0.005433836951851845\n",
            "step = 4800: loss = 0.006370846647769213\n",
            "step = 5000: loss = 0.007445954717695713\n",
            "step = 5000: Average Return = 0.13035406172275543\n",
            "step = 5200: loss = 0.005591885186731815\n",
            "step = 5400: loss = 0.005741295404732227\n",
            "step = 5600: loss = 0.009693749248981476\n",
            "step = 5800: loss = 0.005569770000874996\n",
            "step = 6000: loss = 0.007168885320425034\n",
            "step = 6000: Average Return = 0.0837583914399147\n",
            "step = 6200: loss = 0.004726757761090994\n",
            "step = 6400: loss = 0.006577732507139444\n",
            "step = 6600: loss = 0.006414037197828293\n",
            "step = 6800: loss = 0.007136585656553507\n",
            "step = 7000: loss = 0.0052145663648843765\n",
            "step = 7000: Average Return = 0.10421733558177948\n",
            "step = 7200: loss = 0.00904645025730133\n",
            "step = 7400: loss = 0.005557929631322622\n",
            "step = 7600: loss = 0.006971731781959534\n",
            "step = 7800: loss = 0.00716940313577652\n",
            "step = 8000: loss = 0.006107940338551998\n",
            "step = 8000: Average Return = 0.15041930973529816\n",
            "step = 8200: loss = 0.004848413169384003\n",
            "step = 8400: loss = 0.006091666407883167\n",
            "step = 8600: loss = 0.005921166390180588\n",
            "step = 8800: loss = 0.0051008304581046104\n",
            "step = 9000: loss = 0.006326412782073021\n",
            "step = 9000: Average Return = 0.028379231691360474\n",
            "step = 9200: loss = 0.006634124554693699\n",
            "step = 9400: loss = 0.0074352119117975235\n",
            "step = 9600: loss = 0.005876215640455484\n",
            "step = 9800: loss = 0.003824585350230336\n",
            "step = 10000: loss = 0.007377260364592075\n",
            "step = 10000: Average Return = 0.032549161463975906\n",
            "step = 10200: loss = 0.006738141179084778\n",
            "step = 10400: loss = 0.011955625377595425\n",
            "step = 10600: loss = 0.010331207886338234\n",
            "step = 10800: loss = 0.006698704324662685\n",
            "step = 11000: loss = 0.006484476383775473\n",
            "step = 11000: Average Return = 0.0615571066737175\n",
            "step = 11200: loss = 0.006472492590546608\n",
            "step = 11400: loss = 0.00538611551746726\n",
            "step = 11600: loss = 0.005656050052493811\n",
            "step = 11800: loss = 0.006545389536768198\n",
            "step = 12000: loss = 0.005074695218354464\n",
            "step = 12000: Average Return = 0.10006313025951385\n",
            "step = 12200: loss = 0.005431036464869976\n",
            "step = 12400: loss = 0.01141228899359703\n",
            "step = 12600: loss = 0.006874459329992533\n",
            "step = 12800: loss = 0.005852984264492989\n",
            "step = 13000: loss = 0.0059293764643371105\n",
            "step = 13000: Average Return = 0.10280226171016693\n",
            "step = 13200: loss = 0.007964606396853924\n",
            "step = 13400: loss = 0.008896657265722752\n",
            "step = 13600: loss = 0.00737111596390605\n",
            "step = 13800: loss = 0.00410986365750432\n",
            "step = 14000: loss = 0.004641808569431305\n",
            "step = 14000: Average Return = 0.09041781723499298\n",
            "step = 14200: loss = 0.0038320892490446568\n",
            "step = 14400: loss = 0.007020819932222366\n",
            "step = 14600: loss = 0.00335892615839839\n",
            "step = 14800: loss = 0.005719425156712532\n",
            "step = 15000: loss = 0.005644886288791895\n",
            "step = 15000: Average Return = 0.11093950271606445\n",
            "step = 15200: loss = 0.006213902495801449\n",
            "step = 15400: loss = 0.0053266966715455055\n",
            "step = 15600: loss = 0.004960946273058653\n",
            "step = 15800: loss = 0.004379959776997566\n",
            "step = 16000: loss = 0.0068375952541828156\n",
            "step = 16000: Average Return = 0.1092255488038063\n",
            "step = 16200: loss = 0.005304187536239624\n",
            "step = 16400: loss = 0.004496538080275059\n",
            "step = 16600: loss = 0.005756689235568047\n",
            "step = 16800: loss = 0.005245034582912922\n",
            "step = 17000: loss = 0.004367748275399208\n",
            "step = 17000: Average Return = 0.04721502214670181\n",
            "step = 17200: loss = 0.00580203952267766\n",
            "step = 17400: loss = 0.0064869774505496025\n",
            "step = 17600: loss = 0.004040290601551533\n",
            "step = 17800: loss = 0.004778541158884764\n",
            "step = 18000: loss = 0.00418234895914793\n",
            "step = 18000: Average Return = 0.2056991159915924\n",
            "step = 18200: loss = 0.0059148771688342094\n",
            "step = 18400: loss = 0.009739821776747704\n",
            "step = 18600: loss = 0.00378230307251215\n",
            "step = 18800: loss = 0.006107079330831766\n",
            "step = 19000: loss = 0.005467922426760197\n",
            "step = 19000: Average Return = 0.059283554553985596\n",
            "step = 19200: loss = 0.0054039121605455875\n",
            "step = 19400: loss = 0.006229232996702194\n",
            "step = 19600: loss = 0.008892567828297615\n",
            "step = 19800: loss = 0.004828024655580521\n",
            "step = 20000: loss = 0.005582859739661217\n",
            "step = 20000: Average Return = 0.07226968556642532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as QNetwork_layer_call_fn, QNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses, dense_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV9b3/8deHXUJYEwRZo4KgIlvEDa22VYEqqLUKWqXqLdWqXbz3ttreVmt/bb3a21VbxYrbVdS6tPS6ILbuFiEggoAsAkqQJWFLSCDr5/fHTOghZpKTcCYnwPv5eJzHmfOd7XMmyXzyne93vmPujoiISF1apTsAERFpuZQkREQkkpKEiIhEUpIQEZFIShIiIhJJSUJERCLFliTMrJ+ZvWpmy8xsqZl9u45lzMx+Z2arzWyxmY1KmDfVzFaFr6lxxSkiItEsrvskzKw30NvdF5pZJrAAuMDdlyUsMwG4EZgAnAT81t1PMrPuQB6QC3i47mh33x5LsCIiUqfYahLuvtHdF4bTxcByoE+txSYBj3hgLtA1TC7nAnPcfVuYGOYA4+KKVURE6tamOXZiZgOBkcC7tWb1AdYnfM4Py6LK69r2NGAaQEZGxughQ4akJGYRkUPBggULCt09O2p+7EnCzDoBzwDfcfeiVG/f3acD0wFyc3M9Ly8v1bsQETlomdnH9c2PtXeTmbUlSBCPufuzdSyyAeiX8LlvWBZVLiIizSjO3k0GPAAsd/dfRSw2C7gy7OV0MrDT3TcCs4FzzKybmXUDzgnLRESkGcV5uek04ApgiZktCst+APQHcPd7gRcIejatBkqBq8J528zsp8D8cL3b3X1bjLGKiEgdYksS7v4WYA0s48D1EfNmADNiCE1ERJKkO65FRCSSkoSIiERSkhARkUhKEiIiEklJQkREIilJiIhIJCUJERGJpCQhIiKRlCRERCSSkoSIiERSkhARkUhKEiIiEklJQkREIilJiIhIJCUJERGJpCQhIiKRlCRERCSSkoSIiESK7fGlZjYDOA/Y4u7H1zH/P4HLE+IYCmSHz7deBxQDVUClu+fGFaeIiESLsybxEDAuaqa73+XuI9x9BHAL8Lq7b0tY5KxwvhKEiEiaxJYk3P0NYFuDCwamADPjikVERJom7W0SZtaRoMbxTEKxAy+b2QIzm9bA+tPMLM/M8goKCuIMVUTkkJP2JAGcD7xd61LTWHcfBYwHrjezM6JWdvfp7p7r7rnZ2dlxxyoickhpCUliMrUuNbn7hvB9C/AcMCYNcYmIHPLSmiTMrAvwOeCvCWUZZpZZMw2cA3yQnghFRA5tcXaBnQmcCWSZWT5wK9AWwN3vDRe7EHjZ3UsSVj0ceM7MauJ73N1fiitOERGJFluScPcpSSzzEEFX2cSyNcDweKISEZHGaAltEiIi0kIpSYiISCQlCRERiaQkISIikZQkREQkkpKEiIhEUpIQEZFIShIiIhJJSUJERCIpSYiISCQlCRERiaQkISIikZQkREQkkpKEiIhEUpIQEZFIShIiIhJJSUJERCIpSYiISKTYkoSZzTCzLWb2QcT8M81sp5ktCl8/Tpg3zsxWmNlqM7s5rhhFRKR+cdYkHgLGNbDMm+4+InzdDmBmrYF7gPHAscAUMzs2xjhFRCRCbEnC3d8AtjVh1THAandf4+7lwBPApJQGJyIiSUl3m8QpZva+mb1oZseFZX2A9QnL5IdldTKzaWaWZ2Z5BQUFccYqInLISWeSWAgMcPfhwO+BvzRlI+4+3d1z3T03Ozs7pQGKiBzq0pYk3L3I3XeF0y8Abc0sC9gA9EtYtG9YJiIizSxtScLMepmZhdNjwli2AvOBQWaWY2btgMnArHTFKSJyKGsT14bNbCZwJpBlZvnArUBbAHe/F7gYuM7MKoHdwGR3d6DSzG4AZgOtgRnuvjSuOEVEJJoF5+WDQ25urufl5aU7DBGRA4aZLXD33Kj56e7dJCIiLZiShIiIRFKSEBGRSEoSIiISSUlCREQiKUmIiEgkJQkREYmkJCEiIpGUJEREJJKShIiIRFKSEBGRSEoSIiISSUlCREQiJTVUuJmdCgxMXN7dH4kpJhERaSEaTBJm9ihwFLAIqAqLHVCSEBE5yCVTk8gFjvWD6cETIiKSlGTaJD4AesUdiIiItDzJ1CSygGVmNg8oqyl094mxRSUiIi1CMknitqZs2MxmAOcBW9z9+DrmXw58HzCgGLjO3d8P560Ly6qAyvoerSciIvGpN0mYWWvgPncf0oRtPwTcTXQD91rgc+6+3czGA9OBkxLmn+XuhU3Yr4iIpEi9bRLuXgWsMLP+jd2wu78BbKtn/jvuvj38OBfo29h9iIhIvJK53NQNWBq2SZTUFKa4TeIa4MWEzw68bGZOUJOZHrWimU0DpgH079/oXCYiIvVIJkn8KM4AzOwsgiQxNqF4rLtvMLOewBwz+zCsmXxGmECmA+Tm5qqbrohICjWYJNz99bh2bmYnAH8Cxrv71oR9bgjft5jZc8AYoM4kISIi8WnwPgkzKzazovC1x8yqzKxof3cctnM8C1zh7isTyjPMLLNmGjiH4F4NERFpZsnUJDJrps3MgEnAyQ2tZ2YzgTOBLDPLB24F2obbvBf4MdAD+EOw2b1dXQ8HngvL2gCPu/tLjfpWIiKSEtaU0TbM7D13HxlDPPslNzfX8/Ly0h2GiMgBw8wW1HcvWjID/F2U8LEVwVhOe1IQm4iItHDJ9G46P2G6ElhHcMlJREQOcskkiT+5+9uJBWZ2GrAlnpBERKSlSGYU2N8nWSYiIgeZyJqEmZ0CnApkm9lNCbM6A63jDkxERNKvvstN7YBO4TKZCeVFwMVxBiUiIi1DZJII77R+3cwecvePzayju5c2Y2wiIpJmybRJHGFmy4APAcxsuJn9Id6wRESkJUgmSfwGOBfYChA+GOiMOIMSEZGWIZkkgbuvr1VUFUMsIiLSwiRzn8R6MzsVcDNrC3wbWB5vWCIi0hIkU5O4Frge6ANsAEYA34wzKBERaRmSGQW2ELi85rOZdSNIEj+LMS4REWkBImsSZtbPzKab2f+Z2TXhcx5+CawAejZfiCIiki711SQeAV4HngHGAXnAIuAEd9/UDLGJiEia1Zckurv7beH0bDP7CnC5u1fHH5aIiLQE9bZJhO0PFn7cCnQJn06Hu2+LOTYREUmz+pJEF2AB/0oSAAvDdweOjCsoERFpGSIbrt19oLsf6e45dbySShBmNsPMtpjZBxHzzcx+Z2arzWyxmY1KmDfVzFaFr6mN/2oiIrK/krrjej88RNDoHWU8MCh8TQP+CGBm3YFbgZOAMcCt4aUvERFpRrEmCXd/A6iv7WIS8IgH5gJdzaw3wVhRc9x9m7tvB+ZQf7IREZEYxF2TaEgfIHFcqPywLKr8M8xsmpnlmVleQUFBbIGKiByKkkoSZjbWzK4Kp7PNLCfesJLn7tPdPdfdc7Ozs9MdjojIQaXBJGFmtwLfB24Ji9oC/5ui/W8A+iV87huWRZWLiEgzSqYmcSEwESgBcPdP2fdxpvtjFnBl2MvpZGCnu28EZgPnmFm3sMH6nLBMRESaUTJDhZe7u5uZA5hZRrIbN7OZwJlAlpnlE/RYagvg7vcCLwATgNVAKXBVOG+bmf0UmB9u6nbdvCci0vySSRJPmdl9BD2Pvg5cDdyfzMbdfUoD851gGPK65s0AZiSzHxERiUcyQ4X/0szOBoqAY4Afu/uc2CMTEZG0S6YmQZgUlBhERA4xDSYJMysmGKsp0U6CocP/3d3XxBGYiIikXzI1id8Q3Mz2OMFgf5OBowgG+5tB0DAtIiIHoWS6wE509/vcvdjdi9x9OnCuuz8JaDwlEZGDWDJJotTMLjGzVuHrEmBPOK/2ZSgRETmIJJMkLgeuALYAm8Ppr5rZYcANMcYmIiJplkwX2DXA+RGz30ptOCIi0pIk07upA3ANcBzQoabc3a+OMS4REWkBkrnc9CjQi+AZD68TDLZXHGdQIiLSMiSTJI529x8BJe7+MPAlgifGiYjIQS6ZJFERvu8ws+OBLkDP+EISEZGWIpmb6aaHw3X/F8HQ3p2AH8UalYiItAj1JgkzawUUhc+ZfgM4slmiEhGRFqHey03uXg18r5liERGRFiaZNolXzOw/zKyfmXWvecUemYiIpF0ybRKXhu+JDwdydOlJROSgl8wd1znNEYiIiLQ8DV5uMrOOZvZfZjY9/DzIzM5LZuNmNs7MVpjZajO7uY75vzazReFrpZntSJhXlTBvVmO+lIiIpEYyl5seBBYAp4afNwB/Bv6vvpXMrDVwD3A2wfMo5pvZLHdfVrOMu383YfkbgZEJm9jt7iOS+RIiIhKPZBquj3L3OwlvqnP3UoKHDzVkDLDa3de4eznwBDCpnuWnADOT2K6IiDSTZJJEeTgsuAOY2VFAWRLr9QHWJ3zOD8s+w8wGADnAPxKKO5hZnpnNNbMLktifiIikWDKXm24DXgL6mdljwGnA11Icx2TgaXevSigb4O4bzOxI4B9mtsTdP6q9oplNA6YB9O/fP8VhiYgc2hqsSbj7y8BFBIlhJpDr7q8lse0NQL+Ez33DsrpMptalJnffEL6vAV5j3/aKxOWmu3uuu+dmZ2cnEZaIiCQrmd5NfwPOAV5z9/9z98Iktz0fGGRmOWbWjiARfKaXkpkNIXhW9j8TyrqZWftwOoug9rKs9roiIhKvZNokfgmcDiwzs6fN7OLwQUT1cvdKgsebzgaWA0+5+1Izu93MJiYsOhl4wt0Tn5c9FMgzs/eBV4E7EntFiYhI87B9z831LBh0af088HVgnLt3jjOwpsjNzfW8vLx0hyEicsAwswXunhs1P5mGa8LeTecTDNExCng4NeGJiEhLlswzrp8iuOfhJeBu4PVwdFgRETnIJVOTeACYUtM91czGmtkUd7++gfVEROQAl8wAf7PNbKSZTQEuAdYCz8YemYiIpF1kkjCzwQRDZUwBCoEnCRq6z2qm2EREJM3qq0l8CLwJnOfuqwHM7Lv1LC8iIgeZ+u6TuAjYCLxqZveb2RdIbmA/ERE5SEQmCXf/i7tPBoYQ3ND2HaCnmf3RzM5prgBFRCR9khm7qcTdH3f38wnGX3oP+H7skYmISNolMyzHXu6+PRxQ7wtxBSQiIi1Ho5KEiIgcWpQkREQkkpKEiIhEUpIQEZFIShIiIhJJSUJERCIpSYiISCQlCRERiRRrkjCzcWa2wsxWm9nNdcz/mpkVmNmi8PVvCfOmmtmq8DU1zjhFRKRuST2+tCnCZ2LfA5wN5APzzWyWuy+rteiT7n5DrXW7A7cCuYADC8J1t8cVr4iIfFacNYkxwGp3X+Pu5cATwKQk1z0XmOPu28LEMAcYF1OcIiISIc4k0QdYn/A5Pyyr7ctmttjMnjazfo1cV0REYpTuhuu/AQPd/QSC2sLDjd2AmU0zszwzyysoKEh5gCIih7I4k8QGoF/C575h2V7uvtXdy8KPfwJGJ7tuwjamu3uuu+dmZ2enJHAREQnEmSTmA4PMLMfM2gGTgVmJC5hZ74SPE4Hl4fRs4Bwz62Zm3YBzwjIREWlGsfVucvdKM7uB4OTeGpjh7kvN7HYgz91nAd8ys4lAJbAN+Fq47jYz+ylBogG43d23xRWriIjUzdw93TGkTG5urufl5aU7DBGRA4aZLXD33Kj56W64FhGRFkxJQkREIilJiIhIJCUJERGJpCQhIiKRlCRERCSSkoSIiERSkhARkUhKEiIiEklJQkREIilJiIhIJCUJERGJpCQhIiKRlCRERCSSkoSIiERSkhARkUhKEiIiEklJQkREIsWaJMxsnJmtMLPVZnZzHfNvMrNlZrbYzP5uZgMS5lWZ2aLwNSvOOEVEpG5t4tqwmbUG7gHOBvKB+WY2y92XJSz2HpDr7qVmdh1wJ3BpOG+3u4+IKz4REWlYnDWJMcBqd1/j7uXAE8CkxAXc/VV3Lw0/zgX6xhiPiIg0UpxJog+wPuFzflgW5RrgxYTPHcwsz8zmmtkFcQQoIiL1i+1yU2OY2VeBXOBzCcUD3H2DmR0J/MPMlrj7R3WsOw2YBtC/f/9miVdE5FARZ01iA9Av4XPfsGwfZvZF4IfARHcvqyl39w3h+xrgNWBkXTtx9+nunuvuudnZ2amLvpmUV1anOwQRkUhxJon5wCAzyzGzdsBkYJ9eSmY2EriPIEFsSSjvZmbtw+ks4DQgscH7gFdeWc31jy3klF/8nfztpQ2vICKSBrElCXevBG4AZgPLgafcfamZ3W5mE8PF7gI6AX+u1dV1KJBnZu8DrwJ31OoVdUArr6zm+scX8vySjRSXVfKtme9RUaUahciB7J8fbWVHaXm6w0g5c/d0x5Ayubm5npeXl+4w6lVWWcX1jy3kleVb+MnE4+jasS3ffmIR1591FP957pB0hyciTfDo3I/50V8+YEivTGZ+/WS6ZbRLd0hJM7MF7p4bNV93XDejPRVVXPvoAl5ZvoWfXnA8U08dyKQRfbgkty9/eO0j3lpVmO4QRaSRXl66iVv/+gGjB3RjTWEJV86YR9GeinSHlTJKEs1kT0UV0x5dwKsrCvj5hcO44uS9N5dz28TjODIrg+8+tYiC4rJ6tiIiLcmCj7dz48z3GNa3K49eM4b7vjqaDzcVcdWD8ykpq0x3eCmhJNEMdpdX8fVH8nhzVQF3fvkELjtp3666Hdu14e7LRrFzdwX//uf3qa4+eC4BihysPirYxTUPz6d3lw7MmJpLx3ZtOGtIT343eSSL1u/g3x7OY09FVbrD3G9KEjErLa/kmofn89bqQu66eDiXnNivzuWG9u7Mj847ljdWFnD/m2uaOUoRaYwtxXuYOmMebVoZD189hh6d2u+dN35Yb/7nK8OZu3Yr33h0AWWVB3aiUJKIUUlZJVc9OJ+5a7byq0uGc/Ho+kcd+epJ/Rl3XC/umr2C9z7Z3kxRHho27NjN7KWb2F1+YP/BSvrtKqvk6ofms3VXOQ9MPZEBPTI+s8wFI/twx0XDeH1lATc+fmD3XlSSiMmuskq+9uA85q/bxq8vHcGFIxselsrM+O8vn8DhnTtw48z3DqrGr3T4ZGsp973+EZPueZvT7vgH33h0AZPvn6t2H2myiqpqvvnYQpZvLOYPl49ieL+ukcteemJ/fjLxOF5etpmbnnqfqgP0MrKSRAyK91QwdcY8Fn6yg99NGcmkEfUNWbWvLh3b8rspI9i4cw+3PLuEltZFuayyiuUbi1rsiXZtYQn3vLqa837/Jmfc9Sq/ePFD3J3vjxvCnRefwIpNRVz0x7dZvWVXukOVA4y7c/MzS3hjZQG/uHAYZw3p2eA6U08dyC3jh/C39z/l+88sPiDbG1vE2E0Hk6I9FVz5wDw+2LCTu6eMZPyw3o3exugB3bnp7MHcNXsFpx+dxeQx6RmTauuuMpZvLGbZxp0s31jM8o1FrN6yi8pqxwzGDOzOl07ozbjjetGzc4e0xAiweksxLyzZxAtLNvLhpmIARvbvyg8nDGXc8b3o173j3mWPOTyTax6ez0V/eJvpV+Zy8pE90hW2HGB+NWclzyzM5ztfHBTZtliXb3zuKHZXVPGbV1ZxWNvW3D7pOMwsxkhTSzfTpdDO3RVc+cC7LP20iLsvG8W443s1eVvV1c6VM+aR9/E2Zt0wlsGHZ6Yw0n1VVlWzbmsJyzYWs+zTIpZvDF5bEmoLh3duz9DenRnauzNDemXyUUEJLyzZyOotuzCDEwd0Z8KwXowf1pvDY04Y7s7Kzbt4YclGXliykVVhDLkDujH++N6MO74XR3Q9LHL99dtKueqh+Xy8tYS7Lh7OBSOTr+lJ/HaUlrOjtILWrWzvq5WF02a0akUdZfGedB9792N++NwHTD6xH7+4aFijT/Luzh0vfch9r6/h66fn8IMJQ1tMomjoZjoliRTZUVrOFQ/M48NNRfzh8tGcfezh+73NLcV7mPDbN+me0Y5ZN4ylQ9vWKYg0uGfjL+9t4L1PdrB8UxErNhVTFg402La1cXTPTIb2zuTYMCkM7d2Z7hF3kK7aXMzz4cl65eZ9T9bjh/Wid5fok3Wyyiqr+GRrKWsLS3g/fwcvfrCJNQUle2szE4YFiaExyWlnaQXf+N885q7Zxr+fPZgbPn90i/mjjUN1tVNRXU1llVNZ9a/piqpqKqudyqpqKqqcyurwvaqaqmqn82FtyerUnu4Z7WjXJnVXp3eVVbKusIQ1hSWsC19rt5awtrCEHaVNa4tr0ypIFj0y2nHpif346skDyEroddRUc5Zt5huP5nHmMT2ZfsVo2rRu2nFwd26btZSH//kx3/rCIG46e/B+x5YKShLNYHtJOZf/6V1Wb9nFvVeM4vND9j9B1Hh9ZQFTZ8zjspP68/MLh+3Xtiqrqnl6QT6/eWUVm4r20D2jHUN7ZzK017+SwdE9OzX5ZFDXZZ/RA7oxYVhvxjfw331FVTX523eztnAXawtLgxNHeNLYsGM3Nb+mrQxOOaoH44/vzTnHHU7PzKbXWsorq7n5mcU8+94GvjK6Lz+/aBhtm3gCaCmqq52lnxbxxqoC3lxVwPvrd7KnsopU/Jl3OawtWZ3a0aNTe7I7tadHp3ZkJbxn7f3cnox2rSmrDGqoawuCBBAkg1LWFJZQuGvfNq3eXTowsEcGOdkZ5PTIoHtGO6rdqXanqhqq3Kmudiqrg/cqd6oSpv9VBh9uKuK1FQW0a9OKC0YcwdVjcxjSq3OTvvPCT7Zz2f1zOebwTGZOO5mO7fbvCn11tXPLs0t4Mm893xt3DN888+j92l4qKEnEbOuuMi7/07usKSxh+hWjOfOYhhuzGusXLy7nvtfXcM9lo/jSCY1v46iudl78YBP/8/IK1hSWMKp/V743bggn5XSP7b/njwp28eKSjTy/ZBPLNxYBQTvBl4b15uienfhkWylrCoJEsK6whPXbd+/T+yOzQxtysjIY2CODgVkZ5GR1JCerE0dmZ9C5Q9uUxenu/OaVVfz276sYe3QWf/jqqJRuvzls3LmbN1cV8uaqQt5aVcD28D/xY3t3ZkxOdzI7tKFNq1a0aW20bW20adUqeG/dijatjLatg3mJ5W1bGWbGzt0VbC0po7C4nMJdZf+aLimjsLiMoj1131Xcvk2rvbXTGlmd2pOT1XGfZJCTncGA7hkc1i41teQaq7fs4sG31/LMwnz2VFQz9ugsrhmbw+cGZyd9aWpNwS6+/Md36HxYW5657tSU1EoAqqqdm55axF8Xfcqt5x/LVaflpGS7TaUkERN35/klG/n588vZWlLO/VfmcsbgeJ5nUVFVzVfu/ScfFezihW+dvk9DbEMxvrmqkDtnf8gHG4oYfHgn/vPcIXxxaM9mvbSytrBkb/vB0k+L9pZ3bNeaAT0yODIrg4E1J4+sICn0yGjXrDE+vSCfm59ZzJHZGTx41Rj61FPrSbfS8kreXbuNN1cW8uaqAlaFPbWyM9tz+qAszhiUzWlHZ5GdmZqTWn3KK6vZWlLG1l3lFOwK3gt3lbF1Vxmd2rfdmwwGZnUkMw3Jd0dpOY/P+4RH3vmYTUV7ODI7g6tOy+HLo/rUWysoKC7joj++TWlZFc9cdyoDsz57L8T+qKyq5obH3+OlpZv4xUXDmLKfnVOqq73J7TJKEjH4cFMRt81aytw12zi2d2d+duHxjOzfLdZ9rt9WyoTfvslRPTvx52tPafCyyHufbOfOl1bwzzVb6dvtMG46ezCTRvShdcwNfA35eGsJm3buYWBWBj0z27eodoC3Vxdy7f8uoEPb1jz4tRM5vk+XdIcEBCeA5ZuKeCNMCnnrtlNeVU37Nq0Yk9OdMwZlc/rgLI45PLNFHc+WpKKqmheWbOSBt9ayOH8nXQ5ry5Qx/Zl66oDPtJuVlFUyefpcVm/ZxcxpJzOinnsh9kd5ZTXfeDSP11YW8KtLhn/mXqrqamfn7goKdpVRUFxGYfheUFyWUFZOQXEZHdq24q3vf75JcShJpNDO0gp+/cpKHp37MZkd2vAf5xzDlDH9m+3E+/zijVz/+EKu/dxR3Dy+7mHFV24u5pezV/Dyss30yGjHjZ8/mikn9ad9m9RW5w9WKzcXc9WD89leWs7vp4zkC0NT176UrJ27K1iSv5P383ewJH8neR9vo3BX8JyCIb0yOWNwNqcPyuLEgd1T1pnhUOHuLPh4Ow+8tZbZSzfRyowJw3pzzdgchvfrSkVVNf/2cB5vrS7k/itHp7R9sS57Kqq4+qFgVIbzhx9B0e6KvSf+wl1lVNZxX0W7Nq3I7tSerMygbSg7sz1HdOnAjV8Y1KQYlCRSoKraeSpvPXfNXsGO0nIuP2kAN509OC1jxt/y7BJmzvuER64es8/lrfztpfx6ziqeey+fjHZtmHbGkVw9NoeM9roVprG2FO/hmofyWPrpTn4y8TiuOGVgbPsqLa9k6adFvL9+B4vzd7I4fwfrtv7rSYUDe3RkZP9unD4oi7FHZ6X1fpSDzfptpTz0zjqenL+eXWWVjB7Qje4Z7ZizbDN3XDSs2e5PKi0PHjy2ZMNOemZ2IKtTO7Iz25MVJoDa05nt26S0xqgksZ8WfLyd22YtZcmGnYwZ2J1bJx7LcUek7zLE7vIqJt3zFttKynnh26fTyox7Xl3NY3M/AYOppwzgujOPjuyyKsmp+cN9ZfkWvn56DreMH7rfffHLKqv4cGMxizfsZHGYFFZtKabmn8UjunTghL5dGda3C8P7dmVYny506XhgNaIfiIr3VPDnvHwefGct67ftblHdU5uDkkQTbSnawx0vfcizCzdweOf2/GDCUCYOP6JFXPNdubmYiXe/Rb9uHfl0x252V1RxSW4/vvWFQfV2M5XGqap2bv9b0K993HG9uHpsDmWVVZRVVFNeVU1ZZRXlldWUVVb/q6yiirKq4HNZZXU4v4pPtpWyfGMRFVXB31uPjHac0LcLw/p2ZXjfLpzQt2uzNDRLtKpq56OCXQzq2alF/J03l7QmCTMbB/wWaA38yd3vqDW/PfAIMBrYClzq7uvCebcA1wBVwLfcfXZD+0tFkiivrOahd9byu7+vpryymmtOz+GGs45ucZdtnpz/CTc/u4QJxz+RjJ0AAAmbSURBVPfmpnMGc1R2p3SHdFByd2a8vY7/9/yypO81aN+mFe3btKJdm9Z7p3uFtYQT+nbhhL5d6NP1sEPqRCQtV9qShJm1BlYCZwP5wHxgirsvS1jmm8AJ7n6tmU0GLnT3S83sWGAmMAY4AngFGOzu9Y7zvL9J4vWVBfzkb0tZU1DC54f05EfnHUtOiru+pdKusko6tbDkdbBaubmYguIy2oUn/fZtWidMtwqnW9O2tenkLweUhpJEnGeYMcBqd18TBvIEMAlYlrDMJOC2cPpp4G4L/sImAU+4exmw1sxWh9v7ZxyBfrK1lJ8+v4w5yzYzsEdHZnwtN/ZeDamgBNF8Bh+eGev4WSItVZxnmT7A+oTP+cBJUcu4e6WZ7QR6hOVza60byyhsO0srGP/bN3Dg++OGcPXYgeouKiISOuD/FTWzacA0gP79G99lrUvHtvz8omGclNODXl3UvVBEJFGcSWIDkDjoet+wrK5l8s2sDdCFoAE7mXUBcPfpwHQAMysws4+bGG8WUNjEdeOkuBpHcTWO4mqcgzGuAfXNjDNJzAcGmVkOwQl+MnBZrWVmAVMJ2houBv7h7m5ms4DHzexXBA3Xg4B5De3Q3Zs8eJKZ5dXXeJMuiqtxFFfjKK7GORTjii1JhG0MNwCzCbrAznD3pWZ2O5Dn7rOAB4BHw4bpbQSJhHC5pwgauSuB6xvq2SQiIqkXa5uEu78AvFCr7McJ03uAr0Ss+zPgZ3HGJyIi9Tuwn7CSWtPTHUAExdU4iqtxFFfjHHJxHVTDcoiISGqpJiEiIpGUJEREJNIhnyTMbJyZrTCz1WZ2czPsr5+ZvWpmy8xsqZl9Oyy/zcw2mNmi8DUhYZ1bwvhWmNm5ccVuZuvMbEm4/7ywrLuZzTGzVeF7t7DczOx34b4Xm9mohO1MDZdfZWZT9zOmYxKOySIzKzKz76TjeJnZDDPbYmYfJJSl7PiY2ejw+K8O101qEKiIuO4ysw/DfT9nZl3D8oFmtjvhuN3b0P6jvmMT40rZz83Mcszs3bD8STNLanz8iLieTIhpnZktSsPxijo3pPd3zN0P2RdB19yPgCOBdsD7wLEx77M3MCqcziQYBPFYgjGs/qOO5Y8N42oP5ITxto4jdmAdkFWr7E7g5nD6ZuC/w+kJwIuAAScD74bl3YE14Xu3cLpbCn9emwhu/mn24wWcAYwCPojj+BDcC3RyuM6LwPj9iOscoE04/d8JcQ1MXK7Wdurcf9R3bGJcKfu5AU8Bk8Ppe4HrmhpXrfn/A/w4Dccr6tyQ1t+xQ70msXcQQncvB2oGIYyNu29094XhdDGwnPrHpdo72KG7rwVqBjtsrtgnAQ+H0w8DFySUP+KBuUBXM+sNnAvMcfdt7r4dmAOMS1EsXwA+cvf67qqP7Xi5+xsE9/PU3t9+H59wXmd3n+vBX/MjCdtqdFzu/rK7V4Yf5xKMWhCpgf1HfcdGx1WPRv3cwv+AP08wMGjK4gq3ewnBKNSRYjpeUeeGtP6OHepJoq5BCGMZSLAuZjYQGAm8GxbdEFYbZyRUUaNijCN2B142swUWjIkFcLi7bwynNwE1w+M2Z1w1JrPvH2+6jxek7vj0CadTHR/A1QT/NdbIMbP3zOx1Mzs9Id6o/Ud9x6ZKxc+tB7AjIRGm6nidDmx291UJZc1+vGqdG9L6O3aoJ4m0MbNOwDPAd9y9CPgjcBQwAthIUOVtbmPdfRQwHrjezM5InBn+95GWPtPh9eaJwJ/DopZwvPaRzuMTxcx+SDBqwWNh0Uagv7uPBG4iGP6mc7LbS8F3bHE/t1qmsO8/Is1+vOo4N+zX9vbXoZ4kkh5IMJXMrC3BL8Fj7v4sgLtvdvcqd68G7ieoZtcXY8pjd/cN4fsW4Lkwhs1hNbWmir2lueMKjQcWuvvmMMa0H69Qqo7PBva9JLTf8ZnZ14DzgMvDkwvh5Zyt4fQCguv9gxvYf9R3bLQU/ty2ElxeaVOrvMnCbV0EPJkQb7Mer7rODfVsr3l+x5JpUDlYXwTDkqwhaCiraRQ7LuZ9GsG1wN/UKu+dMP1dguuzAMexb4PeGoLGvJTGDmQAmQnT7xC0JdzFvo1md4bTX2LfRrN5YXl3YC1Bg1m3cLp7Co7bE8BV6T5e1GrITOXx4bONihP2I65xBGOfZddaLhtoHU4fSXCSqHf/Ud+xiXGl7OdGUKtMbLj+ZlPjSjhmr6freBF9bkjr71hsJ8MD5UXQQ2AlwX8IP2yG/Y0lqC4uBhaFrwnAo8CSsHxWrT+mH4bxrSChN0IqYw//AN4PX0trtkdw7ffvwCqCx8jW/LIZcE+47yVAbsK2riZoeFxNwol9P2LLIPjPsUtCWbMfL4LLEBuBCoLrudek8vgAucAH4Tp3E46I0MS4VhNcl675Hbs3XPbL4c93EbAQOL+h/Ud9xybGlbKfW/g7Oy/8rn8G2jc1rrD8IeDaWss25/GKOjek9XdMw3KIiEikQ71NQkRE6qEkISIikZQkREQkkpKEiIhEUpIQEZFIShIiITPbFb4PNLPLUrztH9T6/E4qty8SFyUJkc8aCDQqSSTc+RtlnyTh7qc2MiaRtFCSEPmsO4DTw+cHfNfMWlvwfIb54cB03wAwszPN7E0zm0VwdzNm9pdwgMSlNYMkmtkdwGHh9h4Ly2pqLRZu+4NwnP9LE7b9mpk9bcFzIR6rGfvfzO4Inzmw2Mx+2exHRw4pDf33I3IoupngmQfnAYQn+53ufqKZtQfeNrOXw2VHAcd7MLw1wNXuvs3MDgPmm9kz7n6zmd3g7iPq2NdFBIPdDQeywnXeCOeNJBiu4lPgbeA0M1sOXAgMcXe38GFCInFRTUKkYecAV1rwtLJ3CYZJGBTOm5eQIAC+ZWbvEzzDoV/CclHGAjM9GPRuM/A6cGLCtvM9GAxvEcFlsJ3AHuABM7sIKN3vbydSDyUJkYYZcKO7jwhfOe5eU5Mo2buQ2ZnAF4FT3H048B7QYT/2W5YwXUXwpLlKgpFTnyYY4fWl/di+SIOUJEQ+q5jg8ZE1ZgPXhcM4Y2aDzSyjjvW6ANvdvdTMhhCMtlmjomb9Wt4ELg3bPbIJHq05Lyqw8FkDXdz9BYJRVIc35ouJNJbaJEQ+azFQFV42egj4LcGlnoVh43EBdT/28SXg2rDdYAXBJaca04HFZrbQ3S9PKH8OOIVg9F0Hvufum8IkU5dM4K9m1oGghnNT076iSHI0CqyIiETS5SYREYmkJCEiIpGUJEREJJKShIiIRFKSEBGRSEoSIiISSUlCREQi/X+eRpeLCCdDGAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Hyper-parameters\n",
        "num_iterations = 20000  # @param {type:\"integer\"}\n",
        "\n",
        "collect_steps_per_iteration = 10  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "train_env_gym = BermudanOptionEnv() # american put env\n",
        "eval_env_gym = BermudanOptionEnv() # test case\n",
        "\n",
        "train_env_wrap = gym_wrapper.GymWrapper(train_env_gym)\n",
        "eval_env_wrap = gym_wrapper.GymWrapper(eval_env_gym)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_env_wrap)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_env_wrap)\n",
        "\n",
        "fc_layer_params = (100,) # number of hidden layers\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)\n",
        "\n",
        "# the buffer will update the Q table based on not only the past one step, but some older steps as well.\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# eval_env evaluation\n",
        "\n",
        "# computer average return of the Q network, which in our case is the reward, which is premium option price\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "    total_return = 0.0\n",
        "    for i in range(num_episodes):\n",
        "\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "\n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "# Data Collection\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "    # Add trajectory to the replay buffer\n",
        "    buffer.add_batch(traj)\n",
        "\n",
        "# common loop in RL- especailly DQN\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "    for i in range(steps):\n",
        "        collect_step(env, policy, buffer)\n",
        "\n",
        "# training!!\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "    for j in range(collect_steps_per_iteration):\n",
        "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        avg_return = compute_avg_return(\n",
        "            eval_env, agent.policy, num_eval_episodes)\n",
        "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "        returns.append(avg_return)\n",
        "\n",
        "# plot training iterations\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=2)\n",
        "\n",
        "# save policy\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "tf_policy_saver.save(policy_dir)\n",
        "\n",
        "saved_policy = tf.compat.v2.saved_model.load(policy_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=10000) # 10000 path\n",
        "pricing_dict['RL-DQN - 10000 Path'] = npv\n",
        "pricing_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p0b4oxKwWUp",
        "outputId": "d7016396-d195-4972-b81a-ab30cb263425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'RL-DQN - 10000 Path': 0.10072408,\n",
              " 'Simple Bermudan - Binomial Tree': 0.1685054169178282}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=100) # 100 path\n",
        "pricing_dict['RL-DQN - 100 Path'] = npv\n",
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=1000) # 1000 path\n",
        "pricing_dict['RL-DQN - 1000 Path'] = npv\n",
        "# npv = compute_avg_return(eval_env, agent.policy, num_episodes=100000) # 100000 path\n",
        "# pricing_dict['RL-DQN - 100000 Path'] = npv"
      ],
      "metadata": {
        "id": "8fY1Jg-lJ_Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pricing_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32654yuJNfqP",
        "outputId": "60e6b2b8-cf23-4db0-d878-ed146acbb3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'RL-DQN - 100 Path': 0.09484039,\n",
              " 'RL-DQN - 1000 Path': 0.09903693,\n",
              " 'Simple Bermudan - Binomial Tree': 0.16844989996356916}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Double Deep Q Network**"
      ],
      "metadata": {
        "id": "dMALaov96-EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1234)\n",
        "# Hyper-parameters\n",
        "num_iterations = 20000  # @param {type:\"integer\"}\n",
        "\n",
        "collect_steps_per_iteration = 10  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "train_env_gym = BermudanOptionEnv() # american put env\n",
        "eval_env_gym = BermudanOptionEnv() # test case\n",
        "\n",
        "train_env_wrap = gym_wrapper.GymWrapper(train_env_gym)\n",
        "eval_env_wrap = gym_wrapper.GymWrapper(eval_env_gym)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_env_wrap)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_env_wrap)\n",
        "\n",
        "fc_layer_params = (100,) # number of hidden layers\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DdqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)\n",
        "\n",
        "# the buffer will update the Q table based on not only the past one step, but some older steps as well.\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# eval_env evaluation\n",
        "\n",
        "# computer average return of the Q network, which in our case is the reward, which is premium option price\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "    total_return = 0.0\n",
        "    for i in range(num_episodes):\n",
        "\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "\n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "# Data Collection\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "    # Add trajectory to the replay buffer\n",
        "    buffer.add_batch(traj)\n",
        "\n",
        "# common loop in RL- especailly DQN\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "    for i in range(steps):\n",
        "        collect_step(env, policy, buffer)\n",
        "\n",
        "# training!!\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "    for j in range(collect_steps_per_iteration):\n",
        "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        avg_return = compute_avg_return(\n",
        "            eval_env, agent.policy, num_eval_episodes)\n",
        "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "        returns.append(avg_return)\n",
        "\n",
        "# plot training iterations\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=2)\n",
        "\n",
        "# save policy\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "tf_policy_saver.save(policy_dir)\n",
        "\n",
        "saved_policy = tf.compat.v2.saved_model.load(policy_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3Fgz4vOy7Bci",
        "outputId": "c7562de0-a921-4c56-858a-d554c868905f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 0.007318985648453236\n",
            "step = 400: loss = 0.004914357326924801\n",
            "step = 600: loss = 0.008899414911866188\n",
            "step = 800: loss = 0.008989217691123486\n",
            "step = 1000: loss = 0.008832154795527458\n",
            "step = 1000: Average Return = 0.0008396123303100467\n",
            "step = 1200: loss = 0.0050729564391076565\n",
            "step = 1400: loss = 0.007944485172629356\n",
            "step = 1600: loss = 0.006655403412878513\n",
            "step = 1800: loss = 0.002653733128681779\n",
            "step = 2000: loss = 0.008516775444149971\n",
            "step = 2000: Average Return = 0.1558341532945633\n",
            "step = 2200: loss = 0.006579430773854256\n",
            "step = 2400: loss = 0.0049057030119001865\n",
            "step = 2600: loss = 0.003363823750987649\n",
            "step = 2800: loss = 0.006345344707369804\n",
            "step = 3000: loss = 0.004293972626328468\n",
            "step = 3000: Average Return = 0.018200621008872986\n",
            "step = 3200: loss = 0.004928006790578365\n",
            "step = 3400: loss = 0.004779922775924206\n",
            "step = 3600: loss = 0.007553691975772381\n",
            "step = 3800: loss = 0.01154407113790512\n",
            "step = 4000: loss = 0.0076934886164963245\n",
            "step = 4000: Average Return = 0.17555297911167145\n",
            "step = 4200: loss = 0.005399312824010849\n",
            "step = 4400: loss = 0.004366240464150906\n",
            "step = 4600: loss = 0.005738822277635336\n",
            "step = 4800: loss = 0.004900476895272732\n",
            "step = 5000: loss = 0.007462445646524429\n",
            "step = 5000: Average Return = 0.09211400151252747\n",
            "step = 5200: loss = 0.007625553756952286\n",
            "step = 5400: loss = 0.005808520130813122\n",
            "step = 5600: loss = 0.005514409393072128\n",
            "step = 5800: loss = 0.007837283425033092\n",
            "step = 6000: loss = 0.005219492595642805\n",
            "step = 6000: Average Return = 0.2199600636959076\n",
            "step = 6200: loss = 0.006766249891370535\n",
            "step = 6400: loss = 0.005453757010400295\n",
            "step = 6600: loss = 0.007543059065937996\n",
            "step = 6800: loss = 0.004797704052180052\n",
            "step = 7000: loss = 0.005812829360365868\n",
            "step = 7000: Average Return = 0.0017131849890574813\n",
            "step = 7200: loss = 0.007014694157987833\n",
            "step = 7400: loss = 0.009505661204457283\n",
            "step = 7600: loss = 0.005325092934072018\n",
            "step = 7800: loss = 0.007586631458252668\n",
            "step = 8000: loss = 0.007657913025468588\n",
            "step = 8000: Average Return = 0.026850104331970215\n",
            "step = 8200: loss = 0.007887065410614014\n",
            "step = 8400: loss = 0.005569363012909889\n",
            "step = 8600: loss = 0.007224289700388908\n",
            "step = 8800: loss = 0.005238438956439495\n",
            "step = 9000: loss = 0.007776905316859484\n",
            "step = 9000: Average Return = 0.08292152732610703\n",
            "step = 9200: loss = 0.008537988178431988\n",
            "step = 9400: loss = 0.00501745380461216\n",
            "step = 9600: loss = 0.00525490939617157\n",
            "step = 9800: loss = 0.0043937996961176395\n",
            "step = 10000: loss = 0.005545922089368105\n",
            "step = 10000: Average Return = 0.14392176270484924\n",
            "step = 10200: loss = 0.006672309245914221\n",
            "step = 10400: loss = 0.004700189922004938\n",
            "step = 10600: loss = 0.004503800068050623\n",
            "step = 10800: loss = 0.005564729683101177\n",
            "step = 11000: loss = 0.004862357396632433\n",
            "step = 11000: Average Return = 0.16519324481487274\n",
            "step = 11200: loss = 0.007303591351956129\n",
            "step = 11400: loss = 0.006009829696267843\n",
            "step = 11600: loss = 0.0081047173589468\n",
            "step = 11800: loss = 0.004801508970558643\n",
            "step = 12000: loss = 0.009405910968780518\n",
            "step = 12000: Average Return = 0.14847233891487122\n",
            "step = 12200: loss = 0.007862845435738564\n",
            "step = 12400: loss = 0.0061883823946118355\n",
            "step = 12600: loss = 0.004757151007652283\n",
            "step = 12800: loss = 0.0059978775680065155\n",
            "step = 13000: loss = 0.006101333536207676\n",
            "step = 13000: Average Return = 0.09889797866344452\n",
            "step = 13200: loss = 0.004090659320354462\n",
            "step = 13400: loss = 0.004574777092784643\n",
            "step = 13600: loss = 0.006019644904881716\n",
            "step = 13800: loss = 0.007916399277746677\n",
            "step = 14000: loss = 0.0032870599534362555\n",
            "step = 14000: Average Return = 0.07725001126527786\n",
            "step = 14200: loss = 0.006568853743374348\n",
            "step = 14400: loss = 0.007436690852046013\n",
            "step = 14600: loss = 0.0049207694828510284\n",
            "step = 14800: loss = 0.003373566083610058\n",
            "step = 15000: loss = 0.00551300123333931\n",
            "step = 15000: Average Return = 0.08420684933662415\n",
            "step = 15200: loss = 0.006582321133464575\n",
            "step = 15400: loss = 0.005000175908207893\n",
            "step = 15600: loss = 0.006259666755795479\n",
            "step = 15800: loss = 0.0056442925706505775\n",
            "step = 16000: loss = 0.006127398461103439\n",
            "step = 16000: Average Return = 0.0519636869430542\n",
            "step = 16200: loss = 0.006666697561740875\n",
            "step = 16400: loss = 0.007029391825199127\n",
            "step = 16600: loss = 0.009461197070777416\n",
            "step = 16800: loss = 0.004332263488322496\n",
            "step = 17000: loss = 0.004927004687488079\n",
            "step = 17000: Average Return = 0.031005602329969406\n",
            "step = 17200: loss = 0.004155022092163563\n",
            "step = 17400: loss = 0.005530177615582943\n",
            "step = 17600: loss = 0.007507299073040485\n",
            "step = 17800: loss = 0.002725610276684165\n",
            "step = 18000: loss = 0.0037504108622670174\n",
            "step = 18000: Average Return = 0.1776702105998993\n",
            "step = 18200: loss = 0.005489662755280733\n",
            "step = 18400: loss = 0.004491101019084454\n",
            "step = 18600: loss = 0.0045183924958109856\n",
            "step = 18800: loss = 0.005457191728055477\n",
            "step = 19000: loss = 0.00495394691824913\n",
            "step = 19000: Average Return = 0.06924612820148468\n",
            "step = 19200: loss = 0.004270507954061031\n",
            "step = 19400: loss = 0.004880567081272602\n",
            "step = 19600: loss = 0.007185418624430895\n",
            "step = 19800: loss = 0.005209734663367271\n",
            "step = 20000: loss = 0.004953410476446152\n",
            "step = 20000: Average Return = 0.03201021999120712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as QNetwork_layer_call_fn, QNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses, dense_17_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=10000)\n",
        "pricing_dict['RL-DQQN - 10000 Path'] = npv\n",
        "pricing_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX_S3zurCT-g",
        "outputId": "ac277996-3e57-4a64-90cc-17d997a43fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'RL-DQN - 100 Path': 0.09484039,\n",
              " 'RL-DQN - 1000 Path': 0.09903693,\n",
              " 'RL-DQQN - 10000 Path': 0.10197765,\n",
              " 'Simple Bermudan - Binomial Tree': 0.16844989996356916}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PPO Agent**"
      ],
      "metadata": {
        "id": "PEjhkZQ1DwgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "num_iterations = 20000  # @param {type:\"integer\"}\n",
        "\n",
        "collect_steps_per_iteration = 10  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 2500  # @param {type:\"integer\"}\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "train_env_gym = BermudanOptionEnv() # american put env\n",
        "eval_env_gym = BermudanOptionEnv() # test case\n",
        "\n",
        "train_env_wrap = gym_wrapper.GymWrapper(train_env_gym)\n",
        "eval_env_wrap = gym_wrapper.GymWrapper(eval_env_gym)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_env_wrap)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_env_wrap)\n",
        "\n",
        "# 2. Constructing the Networks: Critic & Value.\n",
        "conv_layers = None\n",
        "fc_layers = [256, 256]\n",
        "train_step = tf.Variable(initial_value=0)\n",
        "actor_network = ActorDistributionNetwork(\n",
        "    input_tensor_spec=train_env.observation_spec(),\n",
        "    output_tensor_spec=train_env.action_spec(),\n",
        "    conv_layer_params=conv_layers,\n",
        "    fc_layer_params=fc_layers,\n",
        "    activation_fn=gelu\n",
        ")\n",
        "\n",
        "value_network = ValueNetwork(\n",
        "    input_tensor_spec=train_env.observation_spec(),\n",
        "    conv_layer_params=conv_layers,\n",
        "    fc_layer_params=fc_layers,\n",
        "    activation_fn=gelu\n",
        ")\n",
        "\n",
        "# optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "optimizer = Yogi(learning_rate=0.00025)\n",
        "#clipping_epsilon = 0.1\n",
        "td_lambda = 0.95\n",
        "gamma = 0.99\n",
        "num_epochs = 10\n",
        "#use_gae = True\n",
        "#entropy_coef = 0.005\n",
        "\n",
        "agent = ppo_agent.PPOAgent(\n",
        "    time_step_spec=train_env.time_step_spec(),\n",
        "    action_spec=train_env.action_spec(),\n",
        "    optimizer=optimizer,\n",
        "    actor_net=actor_network,\n",
        "    value_net=value_network,\n",
        "#    importance_ratio_clipping=clipping_epsilon,\n",
        "    lambda_value=td_lambda,\n",
        "    discount_factor=gamma,\n",
        "#    entropy_regularization=entropy_coef,\n",
        "#    use_gae=use_gae,\n",
        "    num_epochs=num_epochs,\n",
        "    train_step_counter=train_step\n",
        ")\n",
        "\n",
        "agent.initialize()\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)\n",
        "\n",
        "# the buffer will update the Q table based on not only the past one step, but some older steps as well.\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# eval_env evaluation\n",
        "\n",
        "# computer average return of the Q network, which in our case is the reward, which is premium option price\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "    total_return = 0.0\n",
        "    for i in range(num_episodes):\n",
        "\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "\n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "# Data Collection\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "    # Add trajectory to the replay buffer\n",
        "    buffer.add_batch(traj)\n",
        "\n",
        "# common loop in RL- especailly DQN\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "    for i in range(steps):\n",
        "        collect_step(env, policy, buffer)\n",
        "\n",
        "# training!!\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "    for j in range(collect_steps_per_iteration):\n",
        "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        avg_return = compute_avg_return(\n",
        "            eval_env, agent.policy, num_eval_episodes)\n",
        "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "        returns.append(avg_return)\n",
        "        # save policy\n",
        "        tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "        policy_dir = os.path.join(tempdir, 'policy')\n",
        "        tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "        tf_policy_saver.save(policy_dir)\n",
        "\n",
        "        saved_policy = tf.compat.v2.saved_model.load(policy_dir)\n",
        "\n",
        "# plot training iterations\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=2)\n",
        "\n",
        "# save policy\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "tf_policy_saver.save(policy_dir)\n",
        "\n",
        "saved_policy = tf.compat.v2.saved_model.load(policy_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F14EGGqVDyPo",
        "outputId": "c89f7533-01da-469b-a9df-c4662918fca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 0.13657960295677185\n",
            "step = 400: loss = -0.039122067391872406\n",
            "step = 600: loss = 0.3172760307788849\n",
            "step = 800: loss = 0.5384962558746338\n",
            "step = 1000: loss = 0.35453471541404724\n",
            "step = 1000: Average Return = 0.06383291631937027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 1200: loss = 0.4345945417881012\n",
            "step = 1400: loss = 0.1441502869129181\n",
            "step = 1600: loss = 0.1874113380908966\n",
            "step = 1800: loss = 0.11457064747810364\n",
            "step = 2000: loss = 0.44297051429748535\n",
            "step = 2000: Average Return = 0.04190125688910484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 2200: loss = 0.3111964166164398\n",
            "step = 2400: loss = 0.10341902822256088\n",
            "step = 2600: loss = 0.1006758064031601\n",
            "step = 2800: loss = 0.15501634776592255\n",
            "step = 3000: loss = 0.22402936220169067\n",
            "step = 3000: Average Return = 0.01745353266596794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 3200: loss = 0.16677585244178772\n",
            "step = 3400: loss = 0.12372611463069916\n",
            "step = 3600: loss = 0.19889238476753235\n",
            "step = 3800: loss = 0.25193101167678833\n",
            "step = 4000: loss = 0.1527845710515976\n",
            "step = 4000: Average Return = 0.10168111324310303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 4200: loss = 0.20523428916931152\n",
            "step = 4400: loss = 0.22468361258506775\n",
            "step = 4600: loss = 0.1904739886522293\n",
            "step = 4800: loss = 0.2992331385612488\n",
            "step = 5000: loss = 0.22041404247283936\n",
            "step = 5000: Average Return = 0.09086257219314575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 5200: loss = 0.27642327547073364\n",
            "step = 5400: loss = 0.17335611581802368\n",
            "step = 5600: loss = 0.1591019332408905\n",
            "step = 5800: loss = 0.292421817779541\n",
            "step = 6000: loss = 0.21563822031021118\n",
            "step = 6000: Average Return = 0.08574571460485458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 6200: loss = 0.23651579022407532\n",
            "step = 6400: loss = 0.22646808624267578\n",
            "step = 6600: loss = 0.31767889857292175\n",
            "step = 6800: loss = 0.11764249205589294\n",
            "step = 7000: loss = 0.12372787296772003\n",
            "step = 7000: Average Return = 0.036849986761808395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 7200: loss = 0.19086897373199463\n",
            "step = 7400: loss = 0.26087915897369385\n",
            "step = 7600: loss = 0.20855779945850372\n",
            "step = 7800: loss = 0.2973363399505615\n",
            "step = 8000: loss = 0.33139723539352417\n",
            "step = 8000: Average Return = 0.12670768797397614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 8200: loss = 0.21031861007213593\n",
            "step = 8400: loss = 0.20950767397880554\n",
            "step = 8600: loss = 0.2140866369009018\n",
            "step = 8800: loss = 0.22094886004924774\n",
            "step = 9000: loss = 0.14067992568016052\n",
            "step = 9000: Average Return = 0.06395238637924194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 9200: loss = 0.2986491918563843\n",
            "step = 9400: loss = 0.19179925322532654\n",
            "step = 9600: loss = 0.1883305460214615\n",
            "step = 9800: loss = 0.17561747133731842\n",
            "step = 10000: loss = 0.20667767524719238\n",
            "step = 10000: Average Return = 0.1729131042957306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 10200: loss = 0.3152913451194763\n",
            "step = 10400: loss = 0.15011794865131378\n",
            "step = 10600: loss = 0.21752241253852844\n",
            "step = 10800: loss = 0.23612971603870392\n",
            "step = 11000: loss = 0.09867341816425323\n",
            "step = 11000: Average Return = 0.08154674619436264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 11200: loss = 0.30636852979660034\n",
            "step = 11400: loss = 0.22061389684677124\n",
            "step = 11600: loss = 0.12256182730197906\n",
            "step = 11800: loss = 0.1941087543964386\n",
            "step = 12000: loss = 0.24901895225048065\n",
            "step = 12000: Average Return = 0.07665779441595078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 12200: loss = 0.15673457086086273\n",
            "step = 12400: loss = 0.16606755554676056\n",
            "step = 12600: loss = 0.21756406128406525\n",
            "step = 12800: loss = 0.10126706957817078\n",
            "step = 13000: loss = 0.1950487345457077\n",
            "step = 13000: Average Return = 0.21859999001026154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 13200: loss = 0.12795047461986542\n",
            "step = 13400: loss = 0.16562779247760773\n",
            "step = 13600: loss = 0.18070350587368011\n",
            "step = 13800: loss = 0.2197248637676239\n",
            "step = 14000: loss = 0.15284712612628937\n",
            "step = 14000: Average Return = 0.14327669143676758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 14200: loss = 0.17796289920806885\n",
            "step = 14400: loss = 0.19420146942138672\n",
            "step = 14600: loss = 0.213609516620636\n",
            "step = 14800: loss = 0.22474482655525208\n",
            "step = 15000: loss = 0.21791888773441315\n",
            "step = 15000: Average Return = 0.1569899022579193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 15200: loss = 0.2391628473997116\n",
            "step = 15400: loss = 0.2718994617462158\n",
            "step = 15600: loss = 0.2819845974445343\n",
            "step = 15800: loss = 0.23406405746936798\n",
            "step = 16000: loss = 0.4052269458770752\n",
            "step = 16000: Average Return = 0.07469187676906586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 16200: loss = 0.22705894708633423\n",
            "step = 16400: loss = 0.20025552809238434\n",
            "step = 16600: loss = 0.1559785157442093\n",
            "step = 16800: loss = 0.19021940231323242\n",
            "step = 17000: loss = 0.22875261306762695\n",
            "step = 17000: Average Return = 0.11093215644359589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 17200: loss = 0.3023195266723633\n",
            "step = 17400: loss = 0.1850292682647705\n",
            "step = 17600: loss = 0.22554068267345428\n",
            "step = 17800: loss = 0.17256319522857666\n",
            "step = 18000: loss = 0.2730114459991455\n",
            "step = 18000: Average Return = 0.10644765943288803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 18200: loss = 0.23222678899765015\n",
            "step = 18400: loss = 0.2487606257200241\n",
            "step = 18600: loss = 0.2536862790584564\n",
            "step = 18800: loss = 0.2984355092048645\n",
            "step = 19000: loss = 0.14902155101299286\n",
            "step = 19000: Average Return = 0.012897792272269726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 19200: loss = 0.19113090634346008\n",
            "step = 19400: loss = 0.23745110630989075\n",
            "step = 19600: loss = 0.1507067233324051\n",
            "step = 19800: loss = 0.19278112053871155\n",
            "step = 20000: loss = 0.22667014598846436\n",
            "step = 20000: Average Return = 0.11581043899059296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 20200: loss = 0.15218129754066467\n",
            "step = 20400: loss = 0.1780589073896408\n",
            "step = 20600: loss = 0.1864302158355713\n",
            "step = 20800: loss = 0.18791726231575012\n",
            "step = 21000: loss = 0.17231744527816772\n",
            "step = 21000: Average Return = 0.13622918725013733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-04538c6e2c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mpolicy_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'policy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mtf_policy_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPolicySaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mtf_policy_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0msaved_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/policies/policy_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, export_dir, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \"\"\"\n\u001b[1;32m    609\u001b[0m     tf.compat.v2.saved_model.save(\n\u001b[0;32m--> 610\u001b[0;31m         self._policy, export_dir, signatures=self._signatures, options=options)\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mtemp_spec_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}_temp'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPOLICY_SPECS_PBTXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWriteApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SAVE_V2_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m   \u001b[0msave_and_return_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1369\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1370\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1371\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1490\u001b[0m   asset_info, exported_graph = _fill_meta_graph_def(\n\u001b[1;32m   1491\u001b[0m       \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m       options.namespace_whitelist, options.experimental_custom_gradients)\n\u001b[0m\u001b[1;32m   1493\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_aliases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[0mfunction_aliases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_info_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_aliases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_fill_meta_graph_def\u001b[0;34m(meta_graph_def, saveable_view, signature_functions, namespace_whitelist, save_custom_gradients)\u001b[0m\n\u001b[1;32m    966\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msignature_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature_def\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignature_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m   \u001b[0mmeta_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_graph_default_valued_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m   \u001b[0;31m# store tensor_content in litle endian format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"big\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mstrip_graph_default_valued_attrs\u001b[0;34m(meta_graph_def)\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfunction_def\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfunction_node_def\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0m_strip_node_default_valued_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_node_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m   \u001b[0;31m# Tell consumers of this graph that default valued attrs have been stripped.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36m_strip_node_default_valued_attrs\u001b[0;34m(node_def)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0mattrs_to_strip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_is_default_attr_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mattrs_to_strip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=10000) # 10000 path\n",
        "pricing_dict['RL-PPO - 10000 Path'] = npv\n",
        "pricing_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWr-7zvgDyRt",
        "outputId": "1e653b65-4a68-4ba7-c415-4783985813c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'RL-PPO - 10000 Path': 0.098266214,\n",
              " 'Simple Bermudan - Binomial Tree': 0.16844989996356916}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reinforcement Learning Solver for Pricing Bermudan Put Options with *10* Intermediate Decision Points**"
      ],
      "metadata": {
        "id": "pyBwXcacMGXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analytical Solutions - Binomial Tree Option Pricing Method**"
      ],
      "metadata": {
        "id": "HZDuJ0dAMUxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import QuantLib as ql \n",
        "import pandas as pd\n",
        "def get_bermudan_option_with_11_points(): \n",
        "    maturity = ql.Date(1, 3, 2023)\n",
        "    S0=5\n",
        "    K = 5\n",
        "    r = 0.03\n",
        "    sigma = 0.10\n",
        "    d = 0.0\n",
        "    otype = ql.Option.Put\n",
        "    dc = ql.Actual365Fixed()\n",
        "    calendar = ql.NullCalendar()\n",
        "\n",
        "    today = ql.Date(1, 1, 2021)\n",
        "    bermudan1 = ql.Date(1,3,2021)\n",
        "    bermudan2 = ql.Date(1,5,2021)\n",
        "    bermudan3 = ql.Date(1,7,2021)\n",
        "    bermudan4 = ql.Date(1,9,2021)\n",
        "    bermudan5 = ql.Date(1,11,2021)\n",
        "    bermudan6 = ql.Date(1,1,2022)\n",
        "    bermudan7 = ql.Date(1,3,2022)\n",
        "    bermudan8 = ql.Date(1,5,2022)\n",
        "    bermudan9 = ql.Date(1,7,2022)\n",
        "    bermudan10 = ql.Date(1,9,2022)\n",
        "    bermudan11 = ql.Date(1,11,2022)\n",
        "    ql.Settings.instance().evaluationDate = today\n",
        "\n",
        "    payoff = ql.PlainVanillaPayoff(otype, K)\n",
        "\n",
        "    bermudan_exercise = ql.BermudanExercise([bermudan1,bermudan2,bermudan3,bermudan4,bermudan5,bermudan6,bermudan7,bermudan8,bermudan9,bermudan10,bermudan11, maturity])\n",
        "    bermudan_option=ql.VanillaOption(payoff, bermudan_exercise)\n",
        "\n",
        "    american_exercise = ql.AmericanExercise(today, maturity)\n",
        "    american_option = ql.VanillaOption(payoff, american_exercise)\n",
        "\n",
        "    d_ts = ql.YieldTermStructureHandle(ql.FlatForward(today, d, dc))\n",
        "    r_ts = ql.YieldTermStructureHandle(ql.FlatForward(today, r, dc))\n",
        "    sigma_ts = ql.BlackVolTermStructureHandle(ql.BlackConstantVol(today, calendar, sigma, dc))\n",
        "    bsm_process = ql.BlackScholesMertonProcess(ql.QuoteHandle(ql.SimpleQuote(S0)), d_ts, r_ts, sigma_ts)\n",
        "\n",
        "    binomial_engine = ql.BinomialVanillaEngine(bsm_process, \"crr\", 100)\n",
        "    bermudan_option.setPricingEngine(binomial_engine)\n",
        "    return bermudan_option.NPV()"
      ],
      "metadata": {
        "id": "OkfJ-yn-MO3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pricing_dict = {}\n",
        "pricing_dict['Bermudan Put - Binomial Tree'] = get_bermudan_option_with_11_points()\n",
        "pricing_df = pd.DataFrame.from_dict(pricing_dict, orient='index')\n",
        "pricing_df.columns = ['Option Price']\n",
        "print(pricing_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U7g78PbM7H6",
        "outputId": "924b8adb-8167-4a9e-fe7f-c3192788e5cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    Option Price\n",
            "Bermudan Put with 11 Decision Points - Binomial...      0.184841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Reinforcement Learning Solver to Solve Bermudan Put Option with 11 Internmediate Exercising Points**"
      ],
      "metadata": {
        "id": "gja1e5qZNqK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tf_agents.policies import policy_saver\n",
        "import tempfile\n",
        "import random\n",
        "import os\n",
        "from tf_agents.utils import common  # loss function\n",
        "from tf_agents.trajectories import trajectory  # s->s' trajectory\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer  # replay buffer\n",
        "from tf_agents.networks import q_network  # Q net\n",
        "from tf_agents.environments import tf_py_environment  # gym to tf gym\n",
        "from tf_agents.environments import gym_wrapper  # wrap OpenAI gym\n",
        "from tf_agents.agents.dqn import dqn_agent  # DQN Agent\n",
        "from tf_agents.agents.ppo import ppo_agent\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gym\n",
        "import QuantLib as ql  # used for calculating the price of option if we hold it, baseline\n",
        "\n",
        "# Bermudan Put Gym Environment\n",
        "class BermudanOptionEnv(gym.Env): #Bermudan Put\n",
        "    def __init__(self):\n",
        "        self.S0 = 5.0\n",
        "        self.K = 5.0\n",
        "        self.r = 0.03\n",
        "        self.sigma = 0.10\n",
        "        self.T = 2.0\n",
        "        self.N = 732   # 732 days\n",
        "\n",
        "        self.S1 = 0\n",
        "        self.reward = 0\n",
        "        self.current_day = 0    # from day 0 taking N steps to day N\n",
        "\n",
        "        self.action_space = gym.spaces.Discrete(2)         # 0: hold, 1:exercise, the action space, the RL should learn it\n",
        "        self.observation_space = gym.spaces.Box(low=np.array([0, 0]), high=np.array(\n",
        "            [np.inf, 1.0]), dtype=np.float32)      # S in [0, inf], tao in [0, 1]\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 1:        # we exercise the option\n",
        "            reward = max(self.K-self.S1, 0.0) * np.exp(-self.r * self.T * (self.current_day/self.N)) #early payoff\n",
        "            done = True\n",
        "        else:       # we hold the option, wait to the next exercise date\n",
        "            if self.current_day == self.N:    # at maturity\n",
        "                reward = max(self.K-self.S1, 0.0) * np.exp(-self.r * self.T) # payoff after discouted\n",
        "                done = True\n",
        "            else:  # move to tomorrow/next exercise date\n",
        "                reward = 0 # no payoff\n",
        "                # lnS1 - lnS0 = (r - 1/2*sigma^2)*t + sigma * Wt: GBM stock path solution.\n",
        "                self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.current_day/self.N) + self.sigma * np.sqrt(self.current_day/self.N) * np.random.normal()) #GBM process price\n",
        "                self.current_day += 61\n",
        "                done = False # move to next time\n",
        "\n",
        "        tao = 1.0-self.current_day/self.N        # time to maturity, in unit of fraction of total_length\n",
        "        return np.array([self.S1, tao]), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_day = 0\n",
        "        self.S1 = self.S0\n",
        "        tao = 1.0-self.current_day/self.N        # time to maturity, in unit of fraction of total_length\n",
        "        return [self.S1, tao]"
      ],
      "metadata": {
        "id": "ML9r9R3eNpNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deep Q Network**"
      ],
      "metadata": {
        "id": "4A_jKQEXOXKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "num_iterations = 20000  # @param {type:\"integer\"}\n",
        "\n",
        "collect_steps_per_iteration = 10  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "train_env_gym = BermudanOptionEnv() # american put env\n",
        "eval_env_gym = BermudanOptionEnv() # test case\n",
        "\n",
        "train_env_wrap = gym_wrapper.GymWrapper(train_env_gym)\n",
        "eval_env_wrap = gym_wrapper.GymWrapper(eval_env_gym)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_env_wrap)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_env_wrap)\n",
        "\n",
        "fc_layer_params = (100,) # number of hidden layers\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)\n",
        "\n",
        "# the buffer will update the Q table based on not only the past one step, but some older steps as well.\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# eval_env evaluation\n",
        "\n",
        "# computer average return of the Q network, which in our case is the reward, which is premium option price\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "    total_return = 0.0\n",
        "    for i in range(num_episodes):\n",
        "\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "\n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "# Data Collection\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "    # Add trajectory to the replay buffer\n",
        "    buffer.add_batch(traj)\n",
        "\n",
        "# common loop in RL- especailly DQN\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "    for i in range(steps):\n",
        "        collect_step(env, policy, buffer)\n",
        "\n",
        "# training!!\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "    for j in range(collect_steps_per_iteration):\n",
        "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        avg_return = compute_avg_return(\n",
        "            eval_env, agent.policy, num_eval_episodes)\n",
        "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "        returns.append(avg_return)\n",
        "\n",
        "# plot training iterations\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=2)\n",
        "\n",
        "# save policy\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "tf_policy_saver.save(policy_dir)\n",
        "\n",
        "saved_policy = tf.compat.v2.saved_model.load(policy_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UjJTa0ZuOZTI",
        "outputId": "d871a652-0b7a-4c31-f804-502ad8d026ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 0.003650132566690445\n",
            "step = 400: loss = 0.006475348491221666\n",
            "step = 600: loss = 0.008413203060626984\n",
            "step = 800: loss = 0.013374561443924904\n",
            "step = 1000: loss = 0.004942030645906925\n",
            "step = 1000: Average Return = 0.14340226352214813\n",
            "step = 1200: loss = 0.005061009433120489\n",
            "step = 1400: loss = 0.0027110923547297716\n",
            "step = 1600: loss = 0.003538456279784441\n",
            "step = 1800: loss = 0.003514025127515197\n",
            "step = 2000: loss = 0.004538955166935921\n",
            "step = 2000: Average Return = 0.22681978344917297\n",
            "step = 2200: loss = 0.0065576015040278435\n",
            "step = 2400: loss = 0.0043141841888427734\n",
            "step = 2600: loss = 0.0028684635180979967\n",
            "step = 2800: loss = 0.004327934235334396\n",
            "step = 3000: loss = 0.005101171787828207\n",
            "step = 3000: Average Return = 0.1583210825920105\n",
            "step = 3200: loss = 0.004643366206437349\n",
            "step = 3400: loss = 0.006745918653905392\n",
            "step = 3600: loss = 0.004901840817183256\n",
            "step = 3800: loss = 0.005919065326452255\n",
            "step = 4000: loss = 0.004325441550463438\n",
            "step = 4000: Average Return = 0.1470371037721634\n",
            "step = 4200: loss = 0.007761931978166103\n",
            "step = 4400: loss = 0.008118104189634323\n",
            "step = 4600: loss = 0.006041384767740965\n",
            "step = 4800: loss = 0.006110933609306812\n",
            "step = 5000: loss = 0.005432187579572201\n",
            "step = 5000: Average Return = 0.20752906799316406\n",
            "step = 5200: loss = 0.005839062388986349\n",
            "step = 5400: loss = 0.006243962794542313\n",
            "step = 5600: loss = 0.005569073371589184\n",
            "step = 5800: loss = 0.0042880200780928135\n",
            "step = 6000: loss = 0.004361422266811132\n",
            "step = 6000: Average Return = 0.07824530452489853\n",
            "step = 6200: loss = 0.007289126515388489\n",
            "step = 6400: loss = 0.005774189718067646\n",
            "step = 6600: loss = 0.006247584708034992\n",
            "step = 6800: loss = 0.006737261079251766\n",
            "step = 7000: loss = 0.006695919670164585\n",
            "step = 7000: Average Return = 0.24351219832897186\n",
            "step = 7200: loss = 0.006904953625053167\n",
            "step = 7400: loss = 0.010673531331121922\n",
            "step = 7600: loss = 0.006789978127926588\n",
            "step = 7800: loss = 0.007821287028491497\n",
            "step = 8000: loss = 0.008504698053002357\n",
            "step = 8000: Average Return = 0.20734167098999023\n",
            "step = 8200: loss = 0.004878029692918062\n",
            "step = 8400: loss = 0.007877797819674015\n",
            "step = 8600: loss = 0.006280824076384306\n",
            "step = 8800: loss = 0.006189902778714895\n",
            "step = 9000: loss = 0.006738945841789246\n",
            "step = 9000: Average Return = 0.3913760483264923\n",
            "step = 9200: loss = 0.007690620608627796\n",
            "step = 9400: loss = 0.00896933302283287\n",
            "step = 9600: loss = 0.00822205189615488\n",
            "step = 9800: loss = 0.007399626541882753\n",
            "step = 10000: loss = 0.006430978886783123\n",
            "step = 10000: Average Return = 0.16212911903858185\n",
            "step = 10200: loss = 0.007479802705347538\n",
            "step = 10400: loss = 0.005737816449254751\n",
            "step = 10600: loss = 0.007576887961477041\n",
            "step = 10800: loss = 0.005094585474580526\n",
            "step = 11000: loss = 0.010042072273790836\n",
            "step = 11000: Average Return = 0.14434567093849182\n",
            "step = 11200: loss = 0.006613337434828281\n",
            "step = 11400: loss = 0.008976082317531109\n",
            "step = 11600: loss = 0.005796369630843401\n",
            "step = 11800: loss = 0.009911557659506798\n",
            "step = 12000: loss = 0.009347322396934032\n",
            "step = 12000: Average Return = 0.18730628490447998\n",
            "step = 12200: loss = 0.010699836537241936\n",
            "step = 12400: loss = 0.00826102402061224\n",
            "step = 12600: loss = 0.008034149184823036\n",
            "step = 12800: loss = 0.009554717689752579\n",
            "step = 13000: loss = 0.007161244284361601\n",
            "step = 13000: Average Return = 0.13358864188194275\n",
            "step = 13200: loss = 0.008349182084202766\n",
            "step = 13400: loss = 0.005747328978031874\n",
            "step = 13600: loss = 0.0068497126922011375\n",
            "step = 13800: loss = 0.006263301242142916\n",
            "step = 14000: loss = 0.005184328183531761\n",
            "step = 14000: Average Return = 0.04917732626199722\n",
            "step = 14200: loss = 0.005173856392502785\n",
            "step = 14400: loss = 0.0180068239569664\n",
            "step = 14600: loss = 0.005527151748538017\n",
            "step = 14800: loss = 0.00585197051987052\n",
            "step = 15000: loss = 0.00898070726543665\n",
            "step = 15000: Average Return = 0.26364433765411377\n",
            "step = 15200: loss = 0.006895506754517555\n",
            "step = 15400: loss = 0.005604629870504141\n",
            "step = 15600: loss = 0.006037471815943718\n",
            "step = 15800: loss = 0.006325454916805029\n",
            "step = 16000: loss = 0.0071580130606889725\n",
            "step = 16000: Average Return = 0.050672709941864014\n",
            "step = 16200: loss = 0.005141653120517731\n",
            "step = 16400: loss = 0.004872172139585018\n",
            "step = 16600: loss = 0.005821929778903723\n",
            "step = 16800: loss = 0.005079744849354029\n",
            "step = 17000: loss = 0.005555401556193829\n",
            "step = 17000: Average Return = 0.31907278299331665\n",
            "step = 17200: loss = 0.00724073126912117\n",
            "step = 17400: loss = 0.004550459329038858\n",
            "step = 17600: loss = 0.00428263284265995\n",
            "step = 17800: loss = 0.004730819724500179\n",
            "step = 18000: loss = 0.00477604242041707\n",
            "step = 18000: Average Return = 0.2224125862121582\n",
            "step = 18200: loss = 0.003918148577213287\n",
            "step = 18400: loss = 0.006206146907061338\n",
            "step = 18600: loss = 0.005494691431522369\n",
            "step = 18800: loss = 0.005592279601842165\n",
            "step = 19000: loss = 0.006277251522988081\n",
            "step = 19000: Average Return = 0.16101184487342834\n",
            "step = 19200: loss = 0.00444101681932807\n",
            "step = 19400: loss = 0.0051374961622059345\n",
            "step = 19600: loss = 0.005753764882683754\n",
            "step = 19800: loss = 0.004131630528718233\n",
            "step = 20000: loss = 0.004903119523078203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 20000: Average Return = 0.2329680621623993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as QNetwork_layer_call_fn, QNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses, dense_5_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=10000) # 10000 path\n",
        "pricing_dict['RL-DQN - 10000 Path'] = npv\n",
        "pricing_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YjU-INAOfUs",
        "outputId": "b3ad5faf-97c2-4808-fecb-d7fc7e7ae7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bermudan Put with 11 Decision Points - Binomial Tree': 0.18484082892803913,\n",
              " 'RL-DQN - 100 Path': 0.20071062}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Double Deep Q Network**"
      ],
      "metadata": {
        "id": "5taM7pvzOj_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "num_iterations = 20000  # @param {type:\"integer\"}\n",
        "\n",
        "collect_steps_per_iteration = 10  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "train_env_gym = BermudanOptionEnv() # american put env\n",
        "eval_env_gym = BermudanOptionEnv() # test case\n",
        "\n",
        "train_env_wrap = gym_wrapper.GymWrapper(train_env_gym)\n",
        "eval_env_wrap = gym_wrapper.GymWrapper(eval_env_gym)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_env_wrap)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_env_wrap)\n",
        "\n",
        "fc_layer_params = (100,) # number of hidden layers\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DdqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)\n",
        "\n",
        "# the buffer will update the Q table based on not only the past one step, but some older steps as well.\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# eval_env evaluation\n",
        "\n",
        "# computer average return of the Q network, which in our case is the reward, which is premium option price\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "    total_return = 0.0\n",
        "    for i in range(num_episodes):\n",
        "\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "\n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "# Data Collection\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "    # Add trajectory to the replay buffer\n",
        "    buffer.add_batch(traj)\n",
        "\n",
        "# common loop in RL- especailly DQN\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "    for i in range(steps):\n",
        "        collect_step(env, policy, buffer)\n",
        "\n",
        "# training!!\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "    for j in range(collect_steps_per_iteration):\n",
        "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        avg_return = compute_avg_return(\n",
        "            eval_env, agent.policy, num_eval_episodes)\n",
        "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "        returns.append(avg_return)\n",
        "\n",
        "# plot training iterations\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=2)\n",
        "\n",
        "# save policy\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "tf_policy_saver.save(policy_dir)\n",
        "\n",
        "saved_policy = tf.compat.v2.saved_model.load(policy_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sFR9DuSwOl4a",
        "outputId": "5912cd37-f1d4-4185-b176-63d8f769d772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 0.008041481487452984\n",
            "step = 400: loss = 0.0032232266385108232\n",
            "step = 600: loss = 0.009250139817595482\n",
            "step = 800: loss = 0.0109369782730937\n",
            "step = 1000: loss = 0.01306467317044735\n",
            "step = 1000: Average Return = 0.5354942083358765\n",
            "step = 1200: loss = 0.016467757523059845\n",
            "step = 1400: loss = 0.012879880145192146\n",
            "step = 1600: loss = 0.007006361149251461\n",
            "step = 1800: loss = 0.003891587955877185\n",
            "step = 2000: loss = 0.008131193928420544\n",
            "step = 2000: Average Return = 0.1612675040960312\n",
            "step = 2200: loss = 0.009624606929719448\n",
            "step = 2400: loss = 0.00528717739507556\n",
            "step = 2600: loss = 0.004044915083795786\n",
            "step = 2800: loss = 0.004466997925192118\n",
            "step = 3000: loss = 0.0045033651404082775\n",
            "step = 3000: Average Return = 0.12244696915149689\n",
            "step = 3200: loss = 0.0036306665278971195\n",
            "step = 3400: loss = 0.005511815659701824\n",
            "step = 3600: loss = 0.00658235140144825\n",
            "step = 3800: loss = 0.006338194478303194\n",
            "step = 4000: loss = 0.00929323397576809\n",
            "step = 4000: Average Return = 0.24859090149402618\n",
            "step = 4200: loss = 0.006926759146153927\n",
            "step = 4400: loss = 0.007871922105550766\n",
            "step = 4600: loss = 0.0075486465357244015\n",
            "step = 4800: loss = 0.007906712591648102\n",
            "step = 5000: loss = 0.00736301951110363\n",
            "step = 5000: Average Return = 0.24646659195423126\n",
            "step = 5200: loss = 0.009798913262784481\n",
            "step = 5400: loss = 0.007958192378282547\n",
            "step = 5600: loss = 0.008376269601285458\n",
            "step = 5800: loss = 0.0062589989975094795\n",
            "step = 6000: loss = 0.0067062159068882465\n",
            "step = 6000: Average Return = 0.14440123736858368\n",
            "step = 6200: loss = 0.007267446722835302\n",
            "step = 6400: loss = 0.007764493580907583\n",
            "step = 6600: loss = 0.006363417953252792\n",
            "step = 6800: loss = 0.005893305875360966\n",
            "step = 7000: loss = 0.0058836424723267555\n",
            "step = 7000: Average Return = 0.1558239459991455\n",
            "step = 7200: loss = 0.005673126317560673\n",
            "step = 7400: loss = 0.007007124368101358\n",
            "step = 7600: loss = 0.0050561935640871525\n",
            "step = 7800: loss = 0.00892576389014721\n",
            "step = 8000: loss = 0.006352887488901615\n",
            "step = 8000: Average Return = 0.1528853178024292\n",
            "step = 8200: loss = 0.009132228791713715\n",
            "step = 8400: loss = 0.006661452818661928\n",
            "step = 8600: loss = 0.009044235572218895\n",
            "step = 8800: loss = 0.007064569275826216\n",
            "step = 9000: loss = 0.005006598308682442\n",
            "step = 9000: Average Return = 0.3750474452972412\n",
            "step = 9200: loss = 0.010709677822887897\n",
            "step = 9400: loss = 0.008862103335559368\n",
            "step = 9600: loss = 0.007351668551564217\n",
            "step = 9800: loss = 0.007108881138265133\n",
            "step = 10000: loss = 0.007567030377686024\n",
            "step = 10000: Average Return = 0.18959175050258636\n",
            "step = 10200: loss = 0.00705434987321496\n",
            "step = 10400: loss = 0.010605497285723686\n",
            "step = 10600: loss = 0.0058731259778141975\n",
            "step = 10800: loss = 0.006730270572006702\n",
            "step = 11000: loss = 0.011207749135792255\n",
            "step = 11000: Average Return = 0.08771345019340515\n",
            "step = 11200: loss = 0.004757277201861143\n",
            "step = 11400: loss = 0.006423707120120525\n",
            "step = 11600: loss = 0.00645457673817873\n",
            "step = 11800: loss = 0.007684689946472645\n",
            "step = 12000: loss = 0.005905115976929665\n",
            "step = 12000: Average Return = 0.21595361828804016\n",
            "step = 12200: loss = 0.008831115439534187\n",
            "step = 12400: loss = 0.005706010386347771\n",
            "step = 12600: loss = 0.005724331364035606\n",
            "step = 12800: loss = 0.0051912046037614346\n",
            "step = 13000: loss = 0.006215604022145271\n",
            "step = 13000: Average Return = 0.3119807243347168\n",
            "step = 13200: loss = 0.005536871962249279\n",
            "step = 13400: loss = 0.005478694569319487\n",
            "step = 13600: loss = 0.005161514040082693\n",
            "step = 13800: loss = 0.005743793211877346\n",
            "step = 14000: loss = 0.004352930933237076\n",
            "step = 14000: Average Return = 0.2843053340911865\n",
            "step = 14200: loss = 0.007033033296465874\n",
            "step = 14400: loss = 0.005527947098016739\n",
            "step = 14600: loss = 0.00680506182834506\n",
            "step = 14800: loss = 0.005267368163913488\n",
            "step = 15000: loss = 0.003777678357437253\n",
            "step = 15000: Average Return = 0.05512067675590515\n",
            "step = 15200: loss = 0.0048464033752679825\n",
            "step = 15400: loss = 0.00818763580173254\n",
            "step = 15600: loss = 0.00701959989964962\n",
            "step = 15800: loss = 0.005129003431648016\n",
            "step = 16000: loss = 0.009460401721298695\n",
            "step = 16000: Average Return = 0.21331124007701874\n",
            "step = 16200: loss = 0.009697158820927143\n",
            "step = 16400: loss = 0.0042055519297719\n",
            "step = 16600: loss = 0.005697239656001329\n",
            "step = 16800: loss = 0.005704554729163647\n",
            "step = 17000: loss = 0.005109274294227362\n",
            "step = 17000: Average Return = 0.21403703093528748\n",
            "step = 17200: loss = 0.008435290306806564\n",
            "step = 17400: loss = 0.0042239101603627205\n",
            "step = 17600: loss = 0.005076163914054632\n",
            "step = 17800: loss = 0.00566056976094842\n",
            "step = 18000: loss = 0.006766067817807198\n",
            "step = 18000: Average Return = 0.32456526160240173\n",
            "step = 18200: loss = 0.006579682696610689\n",
            "step = 18400: loss = 0.006058409810066223\n",
            "step = 18600: loss = 0.014545222744345665\n",
            "step = 18800: loss = 0.005959699396044016\n",
            "step = 19000: loss = 0.00521648395806551\n",
            "step = 19000: Average Return = 0.23950190842151642\n",
            "step = 19200: loss = 0.008957059122622013\n",
            "step = 19400: loss = 0.004528959281742573\n",
            "step = 19600: loss = 0.005228746682405472\n",
            "step = 19800: loss = 0.007915262132883072\n",
            "step = 20000: loss = 0.005664312280714512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 20000: Average Return = 0.2176072597503662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as QNetwork_layer_call_fn, QNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses, dense_9_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=10000) # 10000 paths\n",
        "pricing_dict['RL-DDQN - 10000 Path'] = npv\n",
        "pricing_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHJh5dMZOu1b",
        "outputId": "74dabecf-3e5a-4a61-9e54-299c2090aba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bermudan Put with 11 Decision Points - Binomial Tree': 0.18484082892803913,\n",
              " 'RL-DDQN - 100 Path': 0.2136646,\n",
              " 'RL-DQN - 100 Path': 0.20071062}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PPO Agent**"
      ],
      "metadata": {
        "id": "Q576utxFFWy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "num_iterations = 20000  # @param {type:\"integer\"}\n",
        "\n",
        "collect_steps_per_iteration = 10  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "train_env_gym = BermudanOptionEnv() # american put env\n",
        "eval_env_gym = BermudanOptionEnv() # test case\n",
        "\n",
        "train_env_wrap = gym_wrapper.GymWrapper(train_env_gym)\n",
        "eval_env_wrap = gym_wrapper.GymWrapper(eval_env_gym)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_env_wrap)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_env_wrap)\n",
        "\n",
        "fc_layer_params = (100,) # number of hidden layers\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = ppo_agent.PPOAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)\n",
        "\n",
        "# the buffer will update the Q table based on not only the past one step, but some older steps as well.\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# eval_env evaluation\n",
        "\n",
        "# computer average return of the Q network, which in our case is the reward, which is premium option price\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "    total_return = 0.0\n",
        "    for i in range(num_episodes):\n",
        "\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "\n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "# Data Collection\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "    # Add trajectory to the replay buffer\n",
        "    buffer.add_batch(traj)\n",
        "\n",
        "# common loop in RL- especailly DQN\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "    for i in range(steps):\n",
        "        collect_step(env, policy, buffer)\n",
        "\n",
        "# training!!\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "    for j in range(collect_steps_per_iteration):\n",
        "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        avg_return = compute_avg_return(\n",
        "            eval_env, agent.policy, num_eval_episodes)\n",
        "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "        returns.append(avg_return)\n",
        "\n",
        "# plot training iterations\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=2)\n",
        "\n",
        "# save policy\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "tf_policy_saver.save(policy_dir)\n",
        "\n",
        "saved_policy = tf.compat.v2.saved_model.load(policy_dir)"
      ],
      "metadata": {
        "id": "aGLKZyvfFY83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=10000) # 10000 path\n",
        "pricing_dict['RL-PPO - 10000 Path'] = npv\n",
        "pricing_dict"
      ],
      "metadata": {
        "id": "iAxqc8gXFY_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reinforcement Learning Solver for Pricing American Put Options**"
      ],
      "metadata": {
        "id": "Sgbz1XFPoIEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analytical Solutions - Binomial Tree Option Pricing Method**"
      ],
      "metadata": {
        "id": "2LZecYpkoMH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import QuantLib as ql \n",
        "import pandas as pd\n",
        "def get_american_put_option(): \n",
        "    maturity = ql.Date(1, 1, 2023)\n",
        "    S0=5\n",
        "    K = 5\n",
        "    r = 0.03\n",
        "    sigma = 0.10\n",
        "    d = 0.0\n",
        "    otype = ql.Option.Put\n",
        "    dc = ql.Actual365Fixed()\n",
        "    calendar = ql.NullCalendar()\n",
        "\n",
        "    today = ql.Date(1, 1, 2021)\n",
        "    ql.Settings.instance().evaluationDate = today\n",
        "\n",
        "    payoff = ql.PlainVanillaPayoff(otype, K)\n",
        "\n",
        "    american_exercise = ql.AmericanExercise(today, maturity)\n",
        "    american_option = ql.VanillaOption(payoff, american_exercise)\n",
        "\n",
        "    d_ts = ql.YieldTermStructureHandle(ql.FlatForward(today, d, dc))\n",
        "    r_ts = ql.YieldTermStructureHandle(ql.FlatForward(today, r, dc))\n",
        "    sigma_ts = ql.BlackVolTermStructureHandle(ql.BlackConstantVol(today, calendar, sigma, dc))\n",
        "    bsm_process = ql.BlackScholesMertonProcess(ql.QuoteHandle(ql.SimpleQuote(S0)), d_ts, r_ts, sigma_ts)\n",
        "\n",
        "    binomial_engine = ql.BinomialVanillaEngine(bsm_process, \"crr\", 100)\n",
        "    american_option.setPricingEngine(binomial_engine)\n",
        "    return american_option.NPV()"
      ],
      "metadata": {
        "id": "kH4NJBngoVP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pricing_dict = {}\n",
        "pricing_dict['American Put - Binomial Tree'] = get_american_put_option()\n",
        "pricing_df = pd.DataFrame.from_dict(pricing_dict, orient='index')\n",
        "pricing_df.columns = ['Option Price']\n",
        "print(pricing_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RayRJ5YTpMG9",
        "outputId": "e2f3599a-0bc1-41c2-9494-5440cb3fd592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              Option Price\n",
            "American Put - Binomial Tree      0.183273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Reinforcement Learning Solver to Solve American Put Options**"
      ],
      "metadata": {
        "id": "kvIRGlTMn-rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tf_agents.policies import policy_saver\n",
        "import tempfile\n",
        "import random\n",
        "import os\n",
        "from tf_agents.utils import common  # loss function\n",
        "from tf_agents.trajectories import trajectory  # s->s' trajectory\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer  # replay buffer\n",
        "from tf_agents.networks import q_network  # Q net\n",
        "from tf_agents.environments import tf_py_environment  # gym to tf gym\n",
        "from tf_agents.environments import gym_wrapper  # wrap OpenAI gym\n",
        "from tf_agents.agents.dqn import dqn_agent  # DQN Agent\n",
        "from tf_agents.agents.ppo import ppo_agent # PPO Agent\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gym\n",
        "import QuantLib as ql  # used for calculating the price of option if we hold it, baseline\n",
        "\n",
        "# American Put Gym Environment\n",
        "class AmericanPutOptionEnv(gym.Env): #American Put\n",
        "    def __init__(self):\n",
        "        self.S0 = 5.0\n",
        "        self.K = 5.0\n",
        "        self.r = 0.03\n",
        "        self.sigma = 0.10\n",
        "        self.T = 2.0\n",
        "        self.N = 730   # 730 days\n",
        "        self.S1 = 0\n",
        "        self.reward = 0\n",
        "        self.current_day = 0    # from day 0 taking N steps to day N\n",
        "        self.action_space = gym.spaces.Discrete(2)         # 0: hold, 1:exercise, the action space, the RL should learn it\n",
        "        self.observation_space = gym.spaces.Box(low=np.array([0, 0]), high=np.array(\n",
        "            [np.inf, 1.0]), dtype=np.float32)      # S in [0, inf], tao in [0, 1]\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 1:        # we exercise the option\n",
        "            reward = max(self.K-self.S1, 0.0) * np.exp(-self.r * self.T * (self.current_day/self.N)) #early payoff\n",
        "            done = True\n",
        "        else:       # we hold the option, wait to the next exercise date\n",
        "            if self.current_day == self.N:    # at maturity\n",
        "                reward = max(self.K-self.S1, 0.0) * np.exp(-self.r * self.T) # payoff after discouted\n",
        "                done = True\n",
        "            else:  # move to tomorrow/next exercise date\n",
        "                reward = 0 # no payoff\n",
        "                self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "                self.current_day += 1\n",
        "                done = False # move to next time\n",
        "\n",
        "        tao = 1.0-self.current_day/self.N        # time to maturity, in unit of years\n",
        "        return np.array([self.S1, tao]), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_day = 0\n",
        "        self.S1 = self.S0\n",
        "        tao = 1.0-self.current_day/self.N        # time to maturity, in unit of years\n",
        "        return [self.S1, tao]"
      ],
      "metadata": {
        "id": "ddbhIOCvoDHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DQN**"
      ],
      "metadata": {
        "id": "8g3IZwkopudQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "num_iterations = 20000  # @param {type:\"integer\"}\n",
        "\n",
        "collect_steps_per_iteration = 10  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "train_env_gym = AmericanPutOptionEnv() # american put env\n",
        "eval_env_gym = AmericanPutOptionEnv() # test case\n",
        "\n",
        "train_env_wrap = gym_wrapper.GymWrapper(train_env_gym)\n",
        "eval_env_wrap = gym_wrapper.GymWrapper(eval_env_gym)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_env_wrap)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_env_wrap)\n",
        "\n",
        "fc_layer_params = (100,) # number of hidden layers\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)\n",
        "\n",
        "# the buffer will update the Q table based on not only the past one step, but some older steps as well.\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# eval_env evaluation\n",
        "\n",
        "# computer average return of the Q network, which in our case is the reward, which is premium option price\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "    total_return = 0.0\n",
        "    for i in range(num_episodes):\n",
        "\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "\n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "# Data Collection\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "    # Add trajectory to the replay buffer\n",
        "    buffer.add_batch(traj)\n",
        "\n",
        "# common loop in RL- especailly DQN\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "    for i in range(steps):\n",
        "        collect_step(env, policy, buffer)\n",
        "\n",
        "# training!!\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "    for j in range(collect_steps_per_iteration):\n",
        "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        avg_return = compute_avg_return(\n",
        "            eval_env, agent.policy, num_eval_episodes)\n",
        "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "        returns.append(avg_return)\n",
        "\n",
        "# plot training iterations\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=2)\n",
        "\n",
        "# save policy\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "tf_policy_saver.save(policy_dir)\n",
        "\n",
        "saved_policy = tf.compat.v2.saved_model.load(policy_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eYDYLdOQpwwe",
        "outputId": "5f369e27-f401-4514-b4e5-0ebad7d709e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 0.00023643898020964116\n",
            "step = 400: loss = 0.0006300238310359418\n",
            "step = 600: loss = 0.0013709557242691517\n",
            "step = 800: loss = 0.0004812780243810266\n",
            "step = 1000: loss = 0.001050292165018618\n",
            "step = 1000: Average Return = 0.25243932008743286\n",
            "step = 1200: loss = 0.002294923411682248\n",
            "step = 1400: loss = 0.001324157346971333\n",
            "step = 1600: loss = 0.0009737137006595731\n",
            "step = 1800: loss = 0.00033609848469495773\n",
            "step = 2000: loss = 0.0008918949170038104\n",
            "step = 2000: Average Return = 0.3274080157279968\n",
            "step = 2200: loss = 0.001077444525435567\n",
            "step = 2400: loss = 0.0012682040687650442\n",
            "step = 2600: loss = 0.001699418993666768\n",
            "step = 2800: loss = 0.00201292522251606\n",
            "step = 3000: loss = 0.0015698145143687725\n",
            "step = 3000: Average Return = 0.286185085773468\n",
            "step = 3200: loss = 0.0009771451586857438\n",
            "step = 3400: loss = 0.0015402529388666153\n",
            "step = 3600: loss = 0.0017577941762283444\n",
            "step = 3800: loss = 0.0036192203406244516\n",
            "step = 4000: loss = 0.0034345537424087524\n",
            "step = 4000: Average Return = 0.16225209832191467\n",
            "step = 4200: loss = 0.0022657541558146477\n",
            "step = 4400: loss = 0.0029815786983817816\n",
            "step = 4600: loss = 0.003208139445632696\n",
            "step = 4800: loss = 0.0029475949704647064\n",
            "step = 5000: loss = 0.002145006787031889\n",
            "step = 5000: Average Return = 0.15195563435554504\n",
            "step = 5200: loss = 0.007364370860159397\n",
            "step = 5400: loss = 0.005103145260363817\n",
            "step = 5600: loss = 0.005189734976738691\n",
            "step = 5800: loss = 0.005047312937676907\n",
            "step = 6000: loss = 0.005048427265137434\n",
            "step = 6000: Average Return = 0.20127198100090027\n",
            "step = 6200: loss = 0.002571165096014738\n",
            "step = 6400: loss = 0.006868514697998762\n",
            "step = 6600: loss = 0.005011531058698893\n",
            "step = 6800: loss = 0.005682526156306267\n",
            "step = 7000: loss = 0.007541341707110405\n",
            "step = 7000: Average Return = 0.042703211307525635\n",
            "step = 7200: loss = 0.004866686649620533\n",
            "step = 7400: loss = 0.0021522128954529762\n",
            "step = 7600: loss = 0.00126378214918077\n",
            "step = 7800: loss = 0.000398542353650555\n",
            "step = 8000: loss = 0.0006552799604833126\n",
            "step = 8000: Average Return = 0.4045493006706238\n",
            "step = 8200: loss = 0.00021978825679980218\n",
            "step = 8400: loss = 8.518707181792706e-05\n",
            "step = 8600: loss = 0.00020181998843327165\n",
            "step = 8800: loss = 0.0002977707772515714\n",
            "step = 9000: loss = 4.961073136655614e-05\n",
            "step = 9000: Average Return = 0.17114855349063873\n",
            "step = 9200: loss = 4.883110523223877e-05\n",
            "step = 9400: loss = 0.00020737925660796463\n",
            "step = 9600: loss = 2.3912723918328993e-05\n",
            "step = 9800: loss = 0.0001374772982671857\n",
            "step = 10000: loss = 0.0004233568615745753\n",
            "step = 10000: Average Return = 0.10349106788635254\n",
            "step = 10200: loss = 0.0005777314654551446\n",
            "step = 10400: loss = 0.0007851728587411344\n",
            "step = 10600: loss = 0.0002669128589332104\n",
            "step = 10800: loss = 0.0004336757701821625\n",
            "step = 11000: loss = 0.0008390965522266924\n",
            "step = 11000: Average Return = 0.19147150218486786\n",
            "step = 11200: loss = 7.564030511275632e-06\n",
            "step = 11400: loss = 0.00010344505426473916\n",
            "step = 11600: loss = 0.0003458332794252783\n",
            "step = 11800: loss = 0.0001066722470568493\n",
            "step = 12000: loss = 0.0001866066741058603\n",
            "step = 12000: Average Return = 0.19010257720947266\n",
            "step = 12200: loss = 0.00019329943461343646\n",
            "step = 12400: loss = 0.000329049420543015\n",
            "step = 12600: loss = 0.00032831067801453173\n",
            "step = 12800: loss = 5.963194780633785e-05\n",
            "step = 13000: loss = 2.3839034838601947e-05\n",
            "step = 13000: Average Return = 0.12778803706169128\n",
            "step = 13200: loss = 0.00018045557953882962\n",
            "step = 13400: loss = 5.351301660994068e-05\n",
            "step = 13600: loss = 0.00013178007793612778\n",
            "step = 13800: loss = 5.114445593790151e-05\n",
            "step = 14000: loss = 0.00019429821986705065\n",
            "step = 14000: Average Return = 0.03495773673057556\n",
            "step = 14200: loss = 0.00010733030649134889\n",
            "step = 14400: loss = 4.926376277580857e-05\n",
            "step = 14600: loss = 5.612403037957847e-05\n",
            "step = 14800: loss = 0.0001473280426580459\n",
            "step = 15000: loss = 0.00032324332278221846\n",
            "step = 15000: Average Return = 0.04104376956820488\n",
            "step = 15200: loss = 6.221950752660632e-05\n",
            "step = 15400: loss = 3.173571894876659e-05\n",
            "step = 15600: loss = 0.00010771244706120342\n",
            "step = 15800: loss = 0.0002693205024115741\n",
            "step = 16000: loss = 0.0001354240666842088\n",
            "step = 16000: Average Return = 0.14785024523735046\n",
            "step = 16200: loss = 0.00020082313858438283\n",
            "step = 16400: loss = 4.617538797901943e-05\n",
            "step = 16600: loss = 5.435743878479116e-05\n",
            "step = 16800: loss = 0.00018811106565408409\n",
            "step = 17000: loss = 0.00019174943736288697\n",
            "step = 17000: Average Return = 0.09509366005659103\n",
            "step = 17200: loss = 0.0005038953386247158\n",
            "step = 17400: loss = 4.3030056986026466e-05\n",
            "step = 17600: loss = 0.00013765867333859205\n",
            "step = 17800: loss = 0.0002254406426800415\n",
            "step = 18000: loss = 0.00021669999114237726\n",
            "step = 18000: Average Return = 0.15343637764453888\n",
            "step = 18200: loss = 0.00036396144423633814\n",
            "step = 18400: loss = 4.84676675114315e-05\n",
            "step = 18600: loss = 9.238662460120395e-05\n",
            "step = 18800: loss = 0.00011841123341582716\n",
            "step = 19000: loss = 7.006266969256103e-05\n",
            "step = 19000: Average Return = 0.063783660531044\n",
            "step = 19200: loss = 5.559947021538392e-05\n",
            "step = 19400: loss = 9.791057527763769e-05\n",
            "step = 19600: loss = 0.00010749814100563526\n",
            "step = 19800: loss = 3.496388308121823e-05\n",
            "step = 20000: loss = 0.0001712536468403414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 20000: Average Return = 0.24572274088859558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as QNetwork_layer_call_fn, QNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses, dense_17_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f3H8deHEGQv2XvIEFAQIoITtSJaFbdYta6WWkdba2u1WrX667bLukpbHK2KE8U6EBUnIgRkz7DDSiDsEEKSz++Pe7AXyEluwj25Ad7Px+M+7rnfsz735OZ+7jnf7/l+zd0REREpTY1UByAiItWXkoSIiIRSkhARkVBKEiIiEkpJQkREQilJiIhIqMiShJm1N7OJZjbPzOaa2Q9LWcbM7BEzyzKzWWbWP27etWa2OHhcG1WcIiISzqK6T8LMWgOt3X26mTUApgEXuvu8uGXOBW4DzgVOAP7q7ieYWVMgE8gAPFh3gLtviiRYEREpVWRnEu6+1t2nB9PbgPlA230WGw486zGTgcZBcjkbmODueUFimAAMiypWEREpXc2q2ImZdQKOA77cZ1ZbYFXc6+ygLKy8tG2PBEYC1KtXb0DPnj2TErOIyOFg2rRpG9y9edj8yJOEmdUHXgV+5O5bk719dx8FjALIyMjwzMzMZO9CROSQZWYrypofaesmM0snliCec/fXSllkNdA+7nW7oCysXEREqlCUrZsM+Bcw393/FLLYOODbQSunQcAWd18LjAeGmlkTM2sCDA3KRESkCkV5uekk4BpgtpnNCMp+DnQAcPcngbeJtWzKAvKB64N5eWb2EDA1WO9Bd8+LMFYRESlFZEnC3T8DrJxlHLglZN5oYHQEoYmISIJ0x7WIiIRSkhARkVBKEiIiEkpJQkREQilJiIhIKCUJEREJpSQhIiKhlCRERCSUkoSIiIRSkhARkVBKEiIiEkpJQkREQilJiIhIKCUJEREJpSQhIiKhlCRERCSUkoSIiIRSkhARkVCRDV9qZqOB84Acd+9TyvyfAlfFxXE00DwY33o5sA0oBorcPSOqOEVEJFyUZxJPA8PCZrr7H9y9n7v3A+4GPnb3vLhFTg/mK0GIiKRIZEnC3T8B8spdMOZK4IWoYhERkcpJeZ2EmdUldsbxalyxA++Z2TQzG1nO+iPNLNPMMnNzc6MMVUTksJPyJAGcD3y+z6Wmk929P3AOcIuZnRq2sruPcvcMd89o3rx51LGKiBxWqkOSGME+l5rcfXXwnAOMBQamIC4RkcNeSpOEmTUCTgPeiCurZ2YN9kwDQ4E5qYlQROTwFmUT2BeAIUAzM8sG7gfSAdz9yWCxi4D33H1H3KotgbFmtie+59393ajiFBGRcJElCXe/MoFlnibWVDa+bCnQN5qoRESkIqpDnYSIiFRTShIiIhJKSUJEREIpSYiISCglCRERCaUkISIioZQkREQklJKEiIiEUpIQEZFQShIiIhJKSUJEREIpSYiISCglCRERCaUkISIioZQkREQklJKEiIiEUpIQEZFQShIiIhIqsiRhZqPNLMfM5oTMH2JmW8xsRvC4L27eMDNbaGZZZnZXVDGKiEjZojyTeBoYVs4yn7p7v+DxIICZpQGPAecAvYArzaxXhHGKiEiIyJKEu38C5FVi1YFAlrsvdfdCYAwwPKnBiYhIQlJdJzHYzGaa2Ttm1jsoawusilsmOygrlZmNNLNMM8vMzc2NMlYRkcNOKpPEdKCju/cF/ga8XpmNuPsod89w94zmzZsnNUARkcNdypKEu2919+3B9NtAupk1A1YD7eMWbReUiYhIFUtZkjCzVmZmwfTAIJaNwFSgm5l1NrNawAhgXKriFBE5nNWMasNm9gIwBGhmZtnA/UA6gLs/CVwKfN/MioCdwAh3d6DIzG4FxgNpwGh3nxtVnCIiEs5i38uHhoyMDM/MzEx1GCIiBw0zm+buGWHzU926SUREqjElCRERCaUkISIioZQkREQklJKEiIiEUpIQEZFQShIiIhJKSUJEREIpSYiISCglCRERCaUkISIioZQkREQklJKEiIiESqircDM7EegUv7y7PxtRTCIiUk2UmyTM7N9AV2AGUBwUO6AkISJyiEvkTCID6OWH0sATIiKSkETqJOYAraIOREREqp9EziSaAfPMbAqwa0+hu18QWVQiIlItJJIkHqjMhs1sNHAekOPufUqZfxXwM8CAbcD33X1mMG95UFYMFJU1tJ6IiESnzCRhZmnA3929ZyW2/TTwKOEV3MuA09x9k5mdA4wCToibf7q7b6jEfkVEJEnKrJNw92JgoZl1qOiG3f0TIK+M+ZPcfVPwcjLQrqL7EBGRaCVyuakJMDeok9ixpzDJdRI3Au/EvXbgPTNzYmcyo8JWNLORwEiADh0qnMtERKQMiSSJX0QZgJmdTixJnBxXfLK7rzazFsAEM1sQnJnsJ0ggowAyMjLUTFdEJInKTRLu/nFUOzezY4F/Aue4+8a4fa4OnnPMbCwwECg1SYiISHTKvU/CzLaZ2dbgUWBmxWa29UB3HNRzvAZc4+6L4srrmVmDPdPAUGL3aoiISBVL5EyiwZ5pMzNgODCovPXM7AVgCNDMzLKB+4H0YJtPAvcBRwKPxzb7dVPXlsDYoKwm8Ly7v1uhdyUiIklhleltw8y+cvfjIojngGRkZHhmZmaqwxAROWiY2bSy7kVLpIO/i+Ne1iDWl1NBEmITEZFqLpHWTefHTRcBy4ldchIRkUNcIknin+7+eXyBmZ0E5EQTkoiIVBeJ9AL7twTLRETkEBN6JmFmg4ETgeZm9uO4WQ2BtKgDExGR1CvrclMtoH6wTIO48q3ApVEGJSIi1UNokgjutP7YzJ529xVmVtfd86swNhERSbFE6iTamNk8YAGAmfU1s8ejDUtERKqDRJLEX4CzgY0AwcBAp0YZlIiIVA+JJAncfdU+RcURxCIiItVMIvdJrDKzEwE3s3Tgh8D8aMMSEZHqIJEziZuAW4C2wGqgH3BzlEGJiEj1kEgvsBuAq/a8NrMmxJLEryKMS0REqoHQMwkza29mo8zsv2Z2YzDOw8PAQqBF1YUoIiKpUtaZxLPAx8CrwDAgE5gBHOvu66ogNhERSbGykkRTd38gmB5vZpcBV7l7SfRhiYhIdVBmnURQ/2DBy41Ao2B0Otw9L+LYREQkxcpKEo2AafwvSQBMD54d6BJVUCIiUj2EVly7eyd37+LunUt5JJQgzGy0meWY2ZyQ+WZmj5hZlpnNMrP+cfOuNbPFwePair81ERE5UAndcX0AniZW6R3mHKBb8BgJPAFgZk2B+4ETgIHA/cGlLxERqUKRJgl3/wQoq+5iOPCsx0wGGptZa2J9RU1w9zx33wRMoOxkIyIiEYj6TKI8bYH4fqGyg7Kw8v2Y2UgzyzSzzNzc3MgCFRE5HCWUJMzsZDO7Pphubmadow0rce4+yt0z3D2jefPmqQ5HROSQUm6SMLP7gZ8BdwdF6cB/krT/1UD7uNftgrKwchERqUKJnElcBFwA7ABw9zXsPZzpgRgHfDto5TQI2OLua4HxwFAzaxJUWA8NykREpAol0lV4obu7mTmAmdVLdONm9gIwBGhmZtnEWiylA7j7k8DbwLlAFpAPXB/MyzOzh4CpwaYe1M17IiJVL5Ek8ZKZ/Z1Yy6PvAjcA/0hk4+5+ZTnznVg35KXNGw2MTmQ/IiISjUS6Cn/YzM4CtgI9gPvcfULkkYmISMolciZBkBSUGEREDjPlJgkz20asr6Z4W4h1HX6Huy+NIjAREUm9RM4k/kLsZrbniXX2NwLoSqyzv9HEKqZFROQQlEgT2Avc/e/uvs3dt7r7KOBsd38RUH9KIiKHsESSRL6ZXW5mNYLH5UBBMG/fy1AiInIISSRJXAVcA+QA64Ppq82sDnBrhLGJiEiKJdIEdilwfsjsz5IbjoiIVCeJtG6qDdwI9AZq7yl39xsijEtERKqBRC43/RtoRWyMh4+Jdba3LcqgRESkekgkSRzl7r8Adrj7M8A3iY0YJyIih7hEksTu4HmzmfUBGgEtogtJRESqi0RuphsVdNd9L7GuvesDv4g0KhERqRbKTBJmVgPYGowz/QnQpUqiEhGRaqHMy03uXgLcWUWxiIhINZNIncT7ZvYTM2tvZk33PCKPTEREUi6ROokrguf4wYEcXXoSETnkJXLHdeeqCERERKqfci83mVldM7vXzEYFr7uZ2XmJbNzMhpnZQjPLMrO7Spn/ZzObETwWmdnmuHnFcfPGVeRNiYhIciRyuekpYBpwYvB6NfAy8N+yVjKzNOAx4Cxi41FMNbNx7j5vzzLufnvc8rcBx8VtYqe790vkTYiISDQSqbju6u6/J7ipzt3ziQ0+VJ6BQJa7L3X3QmAMMLyM5a8EXkhguyIiUkUSSRKFQbfgDmBmXYFdCazXFlgV9zo7KNuPmXUEOgMfxhXXNrNMM5tsZheG7cTMRgbLZebm5iYQloiIJCqRy00PAO8C7c3sOeAk4LokxzECeMXdi+PKOrr7ajPrAnxoZrPdfcm+KwYj5Y0CyMjI0CBIIiJJlEjrpvfMbBowiNhlph+6+4YEtr0aaB/3ul1QVpoR7N3EFndfHTwvNbOPiNVX7JckREQkOom0bnoTGAp85O7/TTBBAEwFuplZZzOrRSwR7NdKycx6Ehsr+4u4siZmdkQw3YzY2cu8fdcVEZFoJVIn8TBwCjDPzF4xs0uDgYjK5O5FxIY3HQ/MB15y97lm9qCZXRC36AhgjLvHXyo6Gsg0s5nAROC38a2iRESkatje381lLBhr0noG8F1gmLs3jDKwysjIyPDMzMxUhyEictAws2nunhE2P5GKa4LWTecT66KjP/BMcsITEZHqLJExrl8ids/Du8CjwMdB77AiInKIS+RM4l/AlXuap5rZyWZ2pbvfUs56IiJykEukCex4MzvOzK4ELgeWAa9FHpmIiKRcaJIws+7Eusq4EtgAvEisovv0KopNRERSrKwziQXAp8B57p4FYGa3l7G8iIgcYsq6T+JiYC0w0cz+YWZnkljHfiIicogITRLu/rq7jwB6Eruh7UdACzN7wsyGVlWAIiKSOuXece3uO9z9eXc/n1j/S18BP4s8MhERSblEuuX4mrtvcvdR7n5mVAGJiEj1UaEkISIihxclCRERCaUkISIioZQkREQklJKEiIiEUpIQEZFQShIiIhJKSUJEREJFmiTMbJiZLTSzLDO7q5T515lZrpnNCB7fiZt3rZktDh7XRhmniIiULqHhSysjGBP7MeAsIBuYambj3H3ePou+6O637rNuU+B+IANwYFqw7qao4hURkf1FeSYxEMhy96XuXgiMAYYnuO7ZwAR3zwsSwwRgWERxiohIiCiTRFtgVdzr7KBsX5eY2Swze8XM2ldwXcxspJllmllmbm5uMuIWEZFAqiuu3wQ6ufuxxM4WnqnoBoIOBzPcPaN58+ZJD1BE5HAWZZJYDbSPe90uKPuau290913By38CAxJdV0REohdlkpgKdDOzzmZWCxgBjItfwMxax728AJgfTI8HhppZEzNrAgwNykREpApF1rrJ3YvM7FZiX+5pwGh3n2tmDwKZ7j4O+IGZXQAUAXnAdcG6eWb2ELFEA/Cgu+dFFauIiJTO3D3VMSRNRkaGZ2ZmpjoMEZGDhplNc/eMsPmprrgWEZFqTElCRERCKUmIiEgoJQk5LGwr2M39b8whZ2tBqkMROagoSchh4eXMbJ75YgUPvDk31aGIHFSUJOSQ5+68OHUV6WnG27PX8fEidd8ikiglCTnkzVi1mYXrt3HvN3vRuVk97n9jDgW7i1MdlshBQUlCDnkvTl1F3VppXDKgHb+8oDfLN+Yz6pOlqQ5L5KCgJCGHtO27ihg3cw3nHdua+kfU5NTuzfnmMa15bGIWq/LyUx2eSLWnJCGHtLdmrSG/sJgrju/wddm95x1NWg3jgXGqxBYpj5KEHNLGTF1Ftxb16d+h8ddlrRvV4Uff6MYHC3KYMG99CqMTqf6UJFJo7ZadTFyYw7aC3akO5ZC0cN02vlq5mSuOb4+Z7TXv+pM6071lfR4YN5edharEFgkTWS+wEi5vRyGPT8zi2ckrKCwqIT3NOL5TU87o2YIhPVrQtXm9/b7UpOL2NHu9uH+7/ealp9XgweF9GDFqMo9NzOInZ/dIQYQi1Z+SRBXasauIf322jFGfLCW/sIhL+rfj3GNbM3npRj5akMv/vTWf/3trPh2a1g0SRnMGdTmS2ulpqQ79oLOrqJjXvspmaO9WNK1Xq9RlBnU5kouOa8uoT5Zycf+2dGlev4qjFKn+lCSqwK6iYp7/ciWPfpjFxh2FDOvdip+c3Z2jWjQA4PQeLbj7nKPJ3pTPRwtzmbgghzFTV/L0pOXUSU/jpKOOZEiPFpzeswVtG9dJ8bs5OLw3dz2b83cz4vj2ZS5397k9eX/eeu4fN5dnbxioMziRfShJRKi4xHn9q9X8acIiVm/eyeAuR3LnsB4c16FJqcu3a1KXqwd15OpBHSnYXczkpRuZuCCHDxfm8P78HAB6tmrAkB4tOKNnC/p3aEzNNFUrlebFqato27gOJ3VtVuZyLRrU5o6h3XngzXm8PXsd3zy2dZnLixxuNOhQBNydCfPW8/B7C1m0fjvHtG3EncN6cPJRzSr1S9XdWZK7I5YwFuQwdXkeRSVO03q1+MsV/Ti1e/MI3sXBa1VePqf8fiI/Pqs7PzizW7nLFxWXMPyxz9m4vZD37ziN+kfot5McPjToUBX7YslGLn5iEiP/PY2iYufxq/oz7taTOKVb80pfyjAzjmpRn++e2oUXRg7iq/vO4omr+tOiwRHc8PRUXspcleR3cXB7KXMVNQwuHbB/hXVpaqbV4KEL+7BuawGPfLA44uhEDi6RJgkzG2ZmC80sy8zuKmX+j81snpnNMrMPzKxj3LxiM5sRPMZFGWcyzFm9hW+PnsKV/5jM2s0F/O6SY3jv9lM595jWSb/O3aB2Oucc05qXbxrM4K5Hcucrs/jzhEUcSmeFlVVUXMLLmdmc1r05bSpQf9O/QxNGHN+e0Z8tY9H6bRFGKHJwiSxJmFka8BhwDtALuNLMeu2z2FdAhrsfC7wC/D5u3k537xc8LogqzgO1Ki+fW56fznl/+4xZ2Zu559yj+einQ7ji+A6R1xc0qJ3O6OuO57IB7fjrB4v5ycuzKCwqiXSf1d0ni3NZt7VgrzusE3XnsJ7Ur12Te1+fo4QrEojyW2wgkOXuS929EBgDDI9fwN0nuvueDnQmA4ldH6gmCotKuOZfXzJxQQ63nXEUn9x5Ot89tUuVNllNT6vB7y89ltu/0Z1Xp2dzw9NTD+ub88ZMWUWz+rU48+gWFV63ab1a/GxYT6Ysy2PsV6sjiE4k+T5amMMf31tIcUk0P2yiTBJtgfiL5dlBWZgbgXfiXtc2s0wzm2xmF4atZGYjg+Uyc3OrdpyAZ79YzvKN+Tx2VX/uGNqDhrXTq3T/e5gZP/xGNx6+rC+Tl27ksie/YO2WnSmJJZVythXwwYIcLhnQjvRKnsVdkdGefu0b8+u357Nl5+GbbOXgsCovnx+OmcGEeesju4pQLSquzexqIAP4Q1xxx6DG/VvAX8ysa2nruvsod89w94zmzauulc/m/EL+9mEWp3RrxpBq0rro0gHteOr648netJOLHpvE/LVbUx1SlXp12mqKS5wrMsq+N6IsNWoY/3dhH/J2FPKn9xYmMTqR5CrYXczNz02nxJ0nrx5AnVrRXMGIMkmsBuL/W9sFZXsxs28A9wAXuPuuPeXuvjp4Xgp8BBwXYawV9sgHWWwr2M093zy6Wt2AdUq35rx802AALn/yCz5bvCHFEVWN2OhzKxnYuekB3zndp20jrh7UkX9PXsGc1VuSFKFIcj0wbi6zV2/hT5f3o1OzepHtJ8okMRXoZmadzawWMALYq5WSmR0H/J1YgsiJK29iZkcE082Ak4B5EcZaIcs27ODZL5ZzeUZ7erZqmOpw9nN064aMveVE2japw3VPTeGVadmpDilyXy7LY/nG/HLvsE7UHUN70LReLe59fQ4lEV3rFamsl6auYszUVdw8pCtn9WoZ6b4iSxLuXgTcCowH5gMvuftcM3vQzPa0VvoDUB94eZ+mrkcDmWY2E5gI/Nbdq02S+O0786lVswY/Hto91aGEat2oDi/dNJgTujTlJy/P5K/vL05pi53dxSV8tDCHO16ayS9en5P0SrYxU1bSoHZNzumTnDumG9VJ5+fnHs2MVZt1H4pUK3NWb+HeN+Zw0lFHcsfQ6DumjPTWUnd/G3h7n7L74qa/EbLeJOCYKGOrrC+XbmT83PXccVZ3WjSonepwytSwdjpPXTeQu16bxZ/fX8Tqzfn86qJjKl2pW1ElJc60lZsYN2MNb81eS96OQurVSmNHYTGO89DwPkm5VLclfzdvz1nHFRntk3pd9qLj2jJm6ip+9+4Czu7diiYhHQVGpai4hGe/WMGHC3Iwgxpm1DBIq2GYGWlm1KjB/6YtVqdSI25e/SNqctFx7ejVpvqd8UrFbc4v5Kb/TOPIerV4ZMRxpNWI/lK3+h+ogJIS5//emk+rhrX5zildUh1OQmrVrMEfL+tLuyZ1eeSDxazdUsDjV/WnQUQtsdydeWu3Mm7mGt6csYY1WwqonV6DM49uyfC+bTitR3P+PGExT368hNaN6nDL6Ucd8D5fn7GawqISrkjSpaY9zIyHhvfh3Ec+5ffjF/Cbi49N6vbLMnPVZn4+djZz12ylZ6sG1K2VRrHHjm9xiVPisc9jiTvF7rgTlHtQDsXubNm5m398uowTux7JjSd35vQeLahRBV8sknwlJc7tL85g/dYCXvreYI6sf0SV7FdJogLemLk6qCjqG1lLgiiYGT8+qzttG9fm52PncPnfJ/P09cfTsmHyzoSWb9jBuJlreGPGapbk7qBmDeOUbs346bAenNWr1V79Id15dg/Wby3gD+MX0qLBEVx2AK2R3J0XpqykT9uG9GnbKBlvZS89WjXghpM68Y9Pl3Fqt+YM69Mq0oYKWwt288fxC3l28gpaNDiCJ67qf0D73JK/mxemruSZScu58ZlMOjerx/UndeLSAe2oW0v//geTv32YxcSFuTw0vHdoJ6FRUAd/CdpZWMwZf/yIZvWP4I1bTjpof419vCiXm/8zjUZ10jm/Xxua1K1F4zrpNK5biyZ1//fcqG46R9QsOxGu21LAf2etYdzMNczKjrUCGti5KcP7teGcPq1Dx3GA2I2INz4zlUlLNvLPazM4vUfFb34DmJW9mQse/ZyHLuzDNYM6lr9CJWzfVcQFj37G0twdHNO2Ebec3pWhvVol9TPg7rwzZx0PjJtL7vZdXDu4E3cM7Z60M77dxSW8M2cd//psGTNXbaZh7ZpceUIHrh3cqULdl0hqfLQwh+ufnsqF/dryp8v7JvWHSnkd/ClJJOjRDxfz8HuLGDNyEIO6HBnJPqrK3DVbuP3FGSzfkE9hcfgNOHVrpdGkbi0a1UmnSb1YAmlcJ52GddL5auUmvlyWhzv0aduQ4X3bcl7f1rRulPgXzvZdRVzx9y9YtmEHY0YO4th2jctfaR8/Hzub16Zn8+XPv0GjOtHdzLirqJix01fzxMdLWLExn6Na1OfmIV25oG+bA+5+ZVVePve9MYeJC3Pp07Yhv77omEodi0S4O9NXbmL0Z8t5Z85azIxzj2nNDSd1qtJfp4eaWdmbeWv2WgZ3iY39kkzZm/I572+f0aphbcbefFLSr2IoSSRBzrYCTv/DR5x0VDNGfTv0WB503J2du4vZlL+bzfmFbM7fzabgeXN+YVC+Z7qQzTv/97rTkfU4v28bLujXhq4HcF9CzrYCLn58EgW7i3n1+yfS8cjE23vnFxYx8FcfMLR3S/50eb9Kx1ARRcUlvDV7LY9PXMLC9dto37QO3zu1K5cOaFfh7lh2F5fwr8+W8Zf3F5Fmxo+H9uDawR2rbIyQ7E35PDNpOWOmrGLbriL6d2jMjSd34ezeLQ/KcUp27Cri3tfn8P789ZzZswWXDmjP4K5HRla5u7OwmDdnreE/k1d8fSYNcH7fNtx3Xi+aNzjwOoOC3cVc/vcvWJa7g3G3nUznCO6HUJJIgrtfm8XLmdm8d/upGuKSWHJJ5unuktztXPLEJBrVSefV759IswQr5F7OXMVPX5nFS98bzMDOTZMWTyJKSpwPF+Tw6MQsZqzaTIsGR/DdU7rwrRM6UC+B8SimrcjjnrFzWLBuG0N7teSBC3qn7LLP9l1FvJy5iqc+X87KvHzaNq7DdSd24vLj20d6dpZMC9dt4+bnprFsww6+cXRLJi/dyNaCIto0qs1F/dtySf92SfvfXZq7nee+XMkr07LZsnM3R7WozzWDOnLesa15LhiBsk6tNO4592guy2h3QP8rd782mxemrOTv1wzg7N6tkhL/vpQkDtDCdds456+fcO2Jnbj//N5J3bb8z7QVm7jqn5Pp0bIBL4wclFCl6qVPTCJvRyEf3HFayu56d3e+WLKRRydmMWnJRhrXTef6Eztz7YkdaVx3/zqZLfm7+e27C3hhykraNKrNL4f3ifxmqEQVlzjvz1/P6M+W8eWyPOrVSuO2M7vxnZM7V+szi5cyV3HfG3NoUDudv47ox4ldm1Gwu5j356/n1WnZfLwolxKH/h0ac8mAdpx3bJsKJ7+i4hLen5/Dc1+u4NPFG6hZwzi7TyuuGdSREzo33evzl5WznZ+/Npspy/MY1KUpv77omEolqD0/gm46rSt3ndOzwusnSkniAH179BRmrNzEJ3eeXuo/vSTPhHnr+d6/Mzmte3NGfTujzPs5snK28Y0/fcLd5/Tke6eV2q1XlZu+chOPT8zi/fk51KuVxtWDO3LjyZ1p0aA27s64mWt46L/z2JS/m+tP7MTtZ3VP6KwjFeas3sJf3l/M+/PX07ddI35/aV96tGqQ6rD2srOwmF+8MYdXpmUzuMuR/PXKfqXeu5SztYCxX63m1enZLFq/nVo1azC0V0suHdCOU7o1L/NyVM7WAsZMXcXzX65k3dYCWjeqzbcGduCKge3LvE+qpMR5KXMVv3oXSIkAAA8pSURBVH57PgVFJdx2+lF877Su1KqZWLKdu2YLFz8+if4dmvDvGwdGmqSVJA7ARwtzuO6pqdz7zaMPmvsiDnbPfbmCe8bO4fKMdvzukmNDzxB+9dY8nvp8OV/cfWZSrv0m0/y1W3n8oyW8NWsN6Wk1uDyjPcs27OCzrA30bd+YX1/Uh95tkt9cN9ncnf/OWsv94+ayrWA3t53Rje8P6VplN2OWJStnGzc/N53FOdu57Yxu/PDMbuXWPbg7s1dv4dVp2bwxcw2b83fTsuERXHhcWy7t345uLRt8vdzkpXn8Z/IKxs9dR1GJc0q3ZlwzqCNn9GxRoS/snG0F/PLNebw1ay3dW9bnNxcfy4COZTcQ2JK/m/Me/ZTdRc5/f3BywpdfK0tJopKKiks495FP2VVUwoTbT0v4F4AcuD+9t5BHPsziB2d248dn7d/1SWFRCYN+8wEDOzXlyWsGpCDCxCzbsIMnP1rCa19lU7tmGj8d1oOrTuhYJXfJJtPG7bt44M15vDlzDUe3bsgfLj02kntSEjX2q2zuGTuHOulp/GVEP07pVvFemHcVFTNxQQ6vTMtm4sJcikucvu0acXK3Zoyfu56snO00qpPO5Rnt+NYJHQ+4wviD+ev5xetzWLu1gKtP6MhPh5U+tEBJifOdZzP5dHEuY0YOLjehJIOSRCU9/+VKfj52Nk9c1Z9zjklOf0CSGHfnZ6/O4qXMbH590TF864S9R5l7e/Zabn5uOk9df3yl76+oShu376JmWo2DphI4zPi567j39Tnk7SjkptO68IMzu5V7L00yFewu5pdvzuWFKasY2Kkpj1x5HK0aHfgNobnbdvHGjNW8Mi2bBeu20bd9Y64+oQPn922T1AHEtu8q4o/vLeTpSctp0eAIHhzeZ7/K6L99sJg/TljELy/ozbUndkravsuiJFEJ2wp2c/rDH9G5WT1e+t7gatUV+OFid3EJI5/N5ONFufz9moy9Kne/PXoKi9dv47OfnXHQ/So/2G3J381Db83jlWnZHNWiPn+49Ngqub9i2YYd3PzcdOav3cr3h3TljrO6R3Kdfkv+bhrVjTaZz1i1mbtencWCdds4u3dLfnlBH1o1qs0ni3K59qkpXNC3DX+5ol+Vfe+UlyR0DaUUT368hA3bC7n3m72UIFIkPa0Gj13Vn2PaNuK2F6YzbcUmINa2/9PFuVyW0V4JIgUa1U3n4cv68vT1x5O/q4hLnpjEr96ax87C4sj2+d9Zazj/b5+xdstOnrrueH42rGdkFblRJwiAfu0b8+ZtJ/OzYT35aGEuZ/3pY574aAk/HPMV3Vs04DcXH1OtvneUJPaxevNO/vnpMob3a0Pf9tHc9SqJqVurJv+67vhYh4rPTGVJ7nZezoyNjXHZgINqOPRDzpAeLRh/+6lcObAD//h0Gef89RO+XLoxqfvYVVTMfW/M4dbnv6Jby/q89YNTOL1n9b+8mIj0tBp8f0hXxv/oVI5t34jfvbuAomLniav7V7s+tXS5aR8/GvMV78xZx4c/GUJb9WlTLazYuIOLH59EnVppFBU73VrW5983npDqsCQwackG7np1Nivz8vn24I7cOaznXh06VsbKjfnc8vx0Zq/ewndO7sydw3oeso1H3J1356yjZaPa9E9B1yjlXW6qXikrxWau2szrM9Zw85CuShDVSMcj6/HU9cczYtRk8guL+cV5vVIdksQ5sWsz3v3RKTw8fhFPTVrGB/Nz+O0lx3zd6qi4JNb9S35hETsLi8kPHrHpomBeMTt2xeZv31XE81NWAkR6p3F1YWbVunGMziQC7h7rI2XDDib+ZEhk4y1I5X2etYFxM9bw4IW9q7RVjSRu2oo8fvrKLJbm7qBJ3XTyC4vZVRTeiWRpatYw+rVvzJ+v6Ef7pnUjilT2SOmZhJkNA/4KpAH/dPff7jP/COBZYACwEbjC3ZcH8+4GbgSKgR+4+/goYx0/dx1Tl2/iVxf1UYKopk46qhknHdUs1WFIGQZ0bMrbPziF0Z8vY+3mAurWSqNOrbTguSZ109PiymruNb9uek3q1Eo7ZC8rHawiSxJmlgY8BpwFZANTzWzcPmNV3whscvejzGwE8DvgCjPrBYwAegNtgPfNrLu7R9KEorCohN+8s4BuLepzxQEMgCMiUDs9jZuHHPiIg1I9RJmyBwJZ7r7U3QuBMcDwfZYZDjwTTL8CnGmxtl/DgTHuvsvdlwFZwfYi8ewXy1mxMZ97vnl0te7ITESkqkX5jdgWWBX3OjsoK3UZdy8CtgBHJrhuUmzZuZu/fZjFKd2aJX2wEBGRg91B37rJzEYCIwE6dOhQztL7a1i7Jr+7pHJd+YqIHOqiPJNYDcRf4G8XlJW6jJnVBBoRq8BOZF0A3H2Uu2e4e0bz5hXv6MvMGNanNd1bVq9ukEVEqoPImsAGX/qLgDOJfcFPBb7l7nPjlrkFOMbdbwoqri9298vNrDfwPLF6iDbAB0C38iquzSwXWFHJkJsBGyq5bpQUV8UoropRXBVzKMbV0d1Df2FHdrnJ3YvM7FZgPLEmsKPdfa6ZPQhkuvs44F/Av80sC8gj1qKJYLmXgHlAEXBLIi2bynqj5TGzzLLaCqeK4qoYxVUxiqtiDse4Iq2TcPe3gbf3KbsvbroAuCxk3V8Bv4oyPhERKZvae4qISCglif8ZleoAQiiuilFcFaO4Kuawi+uQ6rtJRESSS2cSIiISSklCRERCHfZJwsyGmdlCM8sys7uqYH/tzWyimc0zs7lm9sOg/AEzW21mM4LHuXHr3B3Et9DMzo4qdjNbbmazg/1nBmVNzWyCmS0OnpsE5WZmjwT7nmVm/eO2c22w/GIzu/YAY+oRd0xmmNlWM/tRKo6XmY02sxwzmxNXlrTjY2YDguOfFayb0BiWIXH9wcwWBPsea2aNg/JOZrYz7rg9Wd7+w95jJeNK2t/NzDqb2ZdB+YtmVusA4noxLqblZjYjBccr7LshtZ8xdz9sH8Tu31gCdAFqATOBXhHvszXQP5huQOyGw17AA8BPSlm+VxDXEUDnIN60KGIHlgPN9in7PXBXMH0X8Ltg+lzgHcCAQcCXQXlTYGnw3CSYbpLEv9c6oGMqjhdwKtAfmBPF8QGmBMtasO45BxDXUKBmMP27uLg6xS+3z3ZK3X/Ye6xkXEn7uwEvASOC6SeB71c2rn3m/xG4LwXHK+y7IaWfscP9TCKRnmqTyt3Xuvv0YHobMJ+yOy8M6xG3qmKP76n3GeDCuPJnPWYy0NjMWgNnAxPcPc/dNwETgGFJiuVMYIm7l3VXfWTHy90/IXbT5777O+DjE8xr6O6TPfbf/Gzctiocl7u/57FOMwEmE+vaJlQ5+w97jxWOqwwV+rsFv4DPINZ7dNLiCrZ7OfBCWduI6HiFfTek9DN2uCeJKutttjRm1gk4DvgyKLo1OG0cHXeKGhZjFLE78J6ZTbNYx4kALd19bTC9DmiZgrj2GMHe/7ypPl6QvOPTNphOdnwANxD71bhHZzP7ysw+NrNT4uIN23/Ye6ysZPzdjgQ2xyXCZB2vU4D17r44rqzKj9c+3w0p/Ywd7kkiZcysPvAq8CN33wo8AXQF+gFriZ3yVrWT3b0/cA5wi5mdGj8z+PWRkjbTwfXmC4CXg6LqcLz2ksrjE8bM7iHWtc1zQdFaoIO7Hwf8GHjezBomur0kvMdq93fbx5Xs/UOkyo9XKd8NB7S9A3W4J4mEe5tNJjNLJ/YheM7dXwNw9/XuXuzuJcA/+N8gS2ExJj12d18dPOcAY4MY1genqXtOsXOqOq7AOcB0d18fxJjy4xVI1vFZzd6XhA44PjO7DjgPuCr4ciG4nLMxmJ5G7Hp/93L2H/YeKyyJf7eNxC6v1NynvNKCbV0MvBgXb5Uer9K+G8rYXtV8xhKpUDlUH8T6rlpKrKJsT6VY74j3acSuBf5ln/LWcdO3E7s+C7EhXOMr9JYSq8xLauxAPaBB3PQkYnUJf2DvSrPfB9PfZO9KsylBeVNgGbEKsybBdNMkHLcxwPWpPl7sU5GZzOPD/pWK5x5AXMOIdZDZfJ/lmgNpwXQXYl8SZe4/7D1WMq6k/d2InVXGV1zfXNm44o7Zx6k6XoR/N6T0MxbZl+HB8iDWQmARsV8I91TB/k4mdro4C5gRPM4F/g3MDsrH7fPPdE8Q30LiWiMkM/bgH2Bm8Ji7Z3vErv1+ACwG3o/7sBmxMcyXBHFnxG3rBmIVj1nEfbEfQGz1iP1ybBRXVuXHi9hliLXAbmLXc29M5vEBMoA5wTqPEvSIUMm4sohdl97zGXsyWPaS4O87A5gOnF/e/sPeYyXjStrfLfjMTgne68vAEZWNKyh/Grhpn2Wr8niFfTek9DOmbjlERCTU4V4nISIiZVCSEBGRUEoSIiISSklCRERCKUmIiEgoJQmRgJltD547mdm3krztn+/zelIyty8SFSUJkf11AiqUJOLu/A2zV5Jw9xMrGJNISihJiOzvt8ApwfgBt5tZmsXGZ5gadEz3PQAzG2Jmn5rZOGJ3N2NmrwcdJM7d00mimf0WqBNs77mgbM9ZiwXbnhP0839F3LY/MrNXLDYuxHN7+v43s98GYw7MMrOHq/zoyGGlvF8/Ioeju4iNeXAeQPBlv8XdjzezI4DPzey9YNn+QB+PdW8NcIO755lZHWCqmb3q7neZ2a3u3q+UfV1MrLO7vkCzYJ1PgnnHEeuuYg3wOXCSmc0HLgJ6urtbMJiQSFR0JiFSvqHAty02WtmXxLpJ6BbMmxKXIAB+YGYziY3h0D5uuTAnAy94rNO79cDHwPFx2872WGd4M4hdBtsCFAD/MrOLgfwDfnciZVCSECmfAbe5e7/g0dnd95xJ7Ph6IbMhwDeAwe7eF/gKqH0A+90VN11MbKS5ImI9p75CrIfXdw9g+yLlUpIQ2d82YsNH7jEe+H7QjTNm1t3M6pWyXiNgk7vnm1lPYr1t7rF7z/r7+BS4Iqj3aE5saM0pYYEFYw00cve3ifWi2rcib0ykolQnIbK/WUBxcNnoaeCvxC71TA8qj3MpfdjHd4GbgnqDhcQuOe0xCphlZtPd/aq48rHAYGK97zpwp7uvC5JMaRoAb5hZbWJnOD+u3FsUSYx6gRURkVC63CQiIqGUJEREJJSShIiIhFKSEBGRUEoSIiISSklCRERCKUmIiEio/we9XT8YjLe0OwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=10000) # not averaged\n",
        "pricing_dict['RL-DQN - 10000 Path'] = npv\n",
        "pricing_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYn-wx9a0BdR",
        "outputId": "616c5706-29f7-46b4-b646-2529da9331da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'American Put - Binomial Tree': 0.18327259259578063,\n",
              " 'RL-DQN - 100 Path': 0.1414174}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DDQN**"
      ],
      "metadata": {
        "id": "6FLMHVnuBlHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "num_iterations = 20000  # @param {type:\"integer\"}\n",
        "\n",
        "collect_steps_per_iteration = 10  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "train_env_gym = BermudanOptionEnv() # american put env\n",
        "eval_env_gym = BermudanOptionEnv() # test case\n",
        "\n",
        "train_env_wrap = gym_wrapper.GymWrapper(train_env_gym)\n",
        "eval_env_wrap = gym_wrapper.GymWrapper(eval_env_gym)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_env_wrap)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_env_wrap)\n",
        "\n",
        "fc_layer_params = (100,) # number of hidden layers\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DdqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)\n",
        "\n",
        "# the buffer will update the Q table based on not only the past one step, but some older steps as well.\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# eval_env evaluation\n",
        "\n",
        "# computer average return of the Q network, which in our case is the reward, which is premium option price\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "    total_return = 0.0\n",
        "    for i in range(num_episodes):\n",
        "\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "\n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "# Data Collection\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "    # Add trajectory to the replay buffer\n",
        "    buffer.add_batch(traj)\n",
        "\n",
        "# common loop in RL- especailly DQN\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "    for i in range(steps):\n",
        "        collect_step(env, policy, buffer)\n",
        "\n",
        "# training!!\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "    for j in range(collect_steps_per_iteration):\n",
        "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        avg_return = compute_avg_return(\n",
        "            eval_env, agent.policy, num_eval_episodes)\n",
        "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "        returns.append(avg_return)\n",
        "\n",
        "# plot training iterations\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=2)\n",
        "\n",
        "# save policy\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "tf_policy_saver.save(policy_dir)\n",
        "\n",
        "saved_policy = tf.compat.v2.saved_model.load(policy_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H-MHmW8uBnN4",
        "outputId": "31638d92-4c60-452f-dd97-0c7dc006cba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 0.02021465077996254\n",
            "step = 400: loss = 0.002763847354799509\n",
            "step = 600: loss = 0.005606097634881735\n",
            "step = 800: loss = 0.009201876819133759\n",
            "step = 1000: loss = 0.0058450354263186455\n",
            "step = 1000: Average Return = 0.2291295975446701\n",
            "step = 1200: loss = 0.0059221358969807625\n",
            "step = 1400: loss = 0.013148041442036629\n",
            "step = 1600: loss = 0.008572177030146122\n",
            "step = 1800: loss = 0.0015853152144700289\n",
            "step = 2000: loss = 0.003436711383983493\n",
            "step = 2000: Average Return = 0.12069052457809448\n",
            "step = 2200: loss = 0.00722106359899044\n",
            "step = 2400: loss = 0.004956073593348265\n",
            "step = 2600: loss = 0.005854591727256775\n",
            "step = 2800: loss = 0.005530149210244417\n",
            "step = 3000: loss = 0.004943207371979952\n",
            "step = 3000: Average Return = 0.11782469600439072\n",
            "step = 3200: loss = 0.006120596081018448\n",
            "step = 3400: loss = 0.007214024662971497\n",
            "step = 3600: loss = 0.009303277358412743\n",
            "step = 3800: loss = 0.007136041764169931\n",
            "step = 4000: loss = 0.006445133127272129\n",
            "step = 4000: Average Return = 0.20632509887218475\n",
            "step = 4200: loss = 0.00583602674305439\n",
            "step = 4400: loss = 0.0055968258529901505\n",
            "step = 4600: loss = 0.007414278574287891\n",
            "step = 4800: loss = 0.009163696318864822\n",
            "step = 5000: loss = 0.008010726422071457\n",
            "step = 5000: Average Return = 0.08261441439390182\n",
            "step = 5200: loss = 0.008054268546402454\n",
            "step = 5400: loss = 0.010216804221272469\n",
            "step = 5600: loss = 0.006374369841068983\n",
            "step = 5800: loss = 0.009786193259060383\n",
            "step = 6000: loss = 0.005782033782452345\n",
            "step = 6000: Average Return = 0.16670463979244232\n",
            "step = 6200: loss = 0.01162546407431364\n",
            "step = 6400: loss = 0.008142667822539806\n",
            "step = 6600: loss = 0.007877483032643795\n",
            "step = 6800: loss = 0.00852852314710617\n",
            "step = 7000: loss = 0.014919999986886978\n",
            "step = 7000: Average Return = 0.1648748517036438\n",
            "step = 7200: loss = 0.008228997699916363\n",
            "step = 7400: loss = 0.008492162451148033\n",
            "step = 7600: loss = 0.006798822898417711\n",
            "step = 7800: loss = 0.00810293946415186\n",
            "step = 8000: loss = 0.007779604289680719\n",
            "step = 8000: Average Return = 0.14036865532398224\n",
            "step = 8200: loss = 0.007650397717952728\n",
            "step = 8400: loss = 0.007581209298223257\n",
            "step = 8600: loss = 0.006659602280706167\n",
            "step = 8800: loss = 0.005517979152500629\n",
            "step = 9000: loss = 0.006968664936721325\n",
            "step = 9000: Average Return = 0.18476584553718567\n",
            "step = 9200: loss = 0.0052261957898736\n",
            "step = 9400: loss = 0.009406807832419872\n",
            "step = 9600: loss = 0.006054988130927086\n",
            "step = 9800: loss = 0.005629220977425575\n",
            "step = 10000: loss = 0.006422343663871288\n",
            "step = 10000: Average Return = 0.34111765027046204\n",
            "step = 10200: loss = 0.00718818511813879\n",
            "step = 10400: loss = 0.007329272106289864\n",
            "step = 10600: loss = 0.005620724055916071\n",
            "step = 10800: loss = 0.007672000210732222\n",
            "step = 11000: loss = 0.007090258412063122\n",
            "step = 11000: Average Return = 0.3866126239299774\n",
            "step = 11200: loss = 0.006888414733111858\n",
            "step = 11400: loss = 0.00829952023923397\n",
            "step = 11600: loss = 0.009080292657017708\n",
            "step = 11800: loss = 0.007694815751165152\n",
            "step = 12000: loss = 0.006405968219041824\n",
            "step = 12000: Average Return = 0.13925403356552124\n",
            "step = 12200: loss = 0.012789524160325527\n",
            "step = 12400: loss = 0.008110035210847855\n",
            "step = 12600: loss = 0.004816429223865271\n",
            "step = 12800: loss = 0.00875113159418106\n",
            "step = 13000: loss = 0.007315977476537228\n",
            "step = 13000: Average Return = 0.390475332736969\n",
            "step = 13200: loss = 0.012038475833833218\n",
            "step = 13400: loss = 0.006528086494654417\n",
            "step = 13600: loss = 0.006718084216117859\n",
            "step = 13800: loss = 0.006550121586769819\n",
            "step = 14000: loss = 0.01286864373832941\n",
            "step = 14000: Average Return = 0.2868642508983612\n",
            "step = 14200: loss = 0.005463710054755211\n",
            "step = 14400: loss = 0.004545321688055992\n",
            "step = 14600: loss = 0.004541020840406418\n",
            "step = 14800: loss = 0.006058318540453911\n",
            "step = 15000: loss = 0.006467827130109072\n",
            "step = 15000: Average Return = 0.21411581337451935\n",
            "step = 15200: loss = 0.0062047261744737625\n",
            "step = 15400: loss = 0.006220283918082714\n",
            "step = 15600: loss = 0.004914033226668835\n",
            "step = 15800: loss = 0.005210123490542173\n",
            "step = 16000: loss = 0.004845001269131899\n",
            "step = 16000: Average Return = 0.08995243906974792\n",
            "step = 16200: loss = 0.005427336320281029\n",
            "step = 16400: loss = 0.005762535147368908\n",
            "step = 16600: loss = 0.004500608891248703\n",
            "step = 16800: loss = 0.0053022801876068115\n",
            "step = 17000: loss = 0.0063918521627783775\n",
            "step = 17000: Average Return = 0.12985295057296753\n",
            "step = 17200: loss = 0.005119123496115208\n",
            "step = 17400: loss = 0.004601311404258013\n",
            "step = 17600: loss = 0.0073091727681458\n",
            "step = 17800: loss = 0.0056823245249688625\n",
            "step = 18000: loss = 0.005909023806452751\n",
            "step = 18000: Average Return = 0.11599370092153549\n",
            "step = 18200: loss = 0.006228108890354633\n",
            "step = 18400: loss = 0.0051205940544605255\n",
            "step = 18600: loss = 0.00543166184797883\n",
            "step = 18800: loss = 0.008727357722818851\n",
            "step = 19000: loss = 0.004836651962250471\n",
            "step = 19000: Average Return = 0.03672686219215393\n",
            "step = 19200: loss = 0.008266986347734928\n",
            "step = 19400: loss = 0.005242376588284969\n",
            "step = 19600: loss = 0.006121658254414797\n",
            "step = 19800: loss = 0.005801650695502758\n",
            "step = 20000: loss = 0.009767402894794941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 20000: Average Return = 0.0975307822227478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as QNetwork_layer_call_fn, QNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses, dense_21_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tf_agents.policies.greedy_policy.DeterministicWithLogProb_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=10000) # 10000 Paths\n",
        "pricing_dict['RL-DDQN - 10000 Path'] = npv\n",
        "pricing_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN7mvd70iYHU",
        "outputId": "fd005427-a6ef-4354-e124-f8b7685223c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'American Put - Binomial Tree': 0.18327259259578063,\n",
              " 'RL-DDQN - 100 Path': 0.18708532,\n",
              " 'RL-DQN - 100 Path': 0.1414174}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PPO Agent**"
      ],
      "metadata": {
        "id": "nDoPTzh2GFMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "num_iterations = 20000  # @param {type:\"integer\"}\n",
        "\n",
        "collect_steps_per_iteration = 10  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "train_env_gym = BermudanOptionEnv() # american put env\n",
        "eval_env_gym = BermudanOptionEnv() # test case\n",
        "\n",
        "train_env_wrap = gym_wrapper.GymWrapper(train_env_gym)\n",
        "eval_env_wrap = gym_wrapper.GymWrapper(eval_env_gym)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_env_wrap)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_env_wrap)\n",
        "\n",
        "fc_layer_params = (100,) # number of hidden layers\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = ppo_agent.PPOAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)\n",
        "\n",
        "# the buffer will update the Q table based on not only the past one step, but some older steps as well.\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# eval_env evaluation\n",
        "\n",
        "# computer average return of the Q network, which in our case is the reward, which is premium option price\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "    total_return = 0.0\n",
        "    for i in range(num_episodes):\n",
        "\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "\n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "# Data Collection\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "    # Add trajectory to the replay buffer\n",
        "    buffer.add_batch(traj)\n",
        "\n",
        "# common loop in RL- especailly DQN\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "    for i in range(steps):\n",
        "        collect_step(env, policy, buffer)\n",
        "\n",
        "# training!!\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "    for j in range(collect_steps_per_iteration):\n",
        "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        avg_return = compute_avg_return(\n",
        "            eval_env, agent.policy, num_eval_episodes)\n",
        "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "        returns.append(avg_return)\n",
        "\n",
        "# plot training iterations\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=2)\n",
        "\n",
        "# save policy\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "tf_policy_saver.save(policy_dir)\n",
        "\n",
        "saved_policy = tf.compat.v2.saved_model.load(policy_dir)"
      ],
      "metadata": {
        "id": "HB5sZ8AGGHCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=10000) # 10000 path\n",
        "pricing_dict['RL-PPO - 10000 Path'] = npv\n",
        "pricing_dict"
      ],
      "metadata": {
        "id": "AquXEwUwGHK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build & Abandon Case**"
      ],
      "metadata": {
        "id": "8g9m3Qkqae97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install tf-agents[reverb]\n",
        "!pip install pyglet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmglQTflNyYq",
        "outputId": "cd977138-289c-4953-dfb4-2cdfcab4c14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [813 kB]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,297 kB]\n",
            "Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,022 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,293 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,040 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,036 kB]\n",
            "Get:21 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:22 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [47.7 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,861 kB]\n",
            "Get:26 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,006 kB]\n",
            "Get:27 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,521 kB]\n",
            "Fetched 16.4 MB in 11s (1,534 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "freeglut3-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libavcodec-dev libavcodec57 libavdevice57 libavfilter6 libavformat-dev\n",
            "  libavformat57 libavresample-dev libavresample3 libavutil-dev libavutil55\n",
            "  libpostproc54 libswresample-dev libswresample2 libswscale-dev libswscale4\n",
            "Suggested packages:\n",
            "  ffmpeg-doc\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "The following packages will be upgraded:\n",
            "  ffmpeg libavcodec-dev libavcodec57 libavdevice57 libavfilter6\n",
            "  libavformat-dev libavformat57 libavresample-dev libavresample3 libavutil-dev\n",
            "  libavutil55 libpostproc54 libswresample-dev libswresample2 libswscale-dev\n",
            "  libswscale4\n",
            "16 upgraded, 1 newly installed, 0 to remove and 73 not upgraded.\n",
            "Need to get 16.2 MB of archives.\n",
            "After this operation, 2,277 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavformat-dev amd64 7:3.4.11-0ubuntu0.1 [1,133 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavcodec-dev amd64 7:3.4.11-0ubuntu0.1 [5,084 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libswresample-dev amd64 7:3.4.11-0ubuntu0.1 [68.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libswresample2 amd64 7:3.4.11-0ubuntu0.1 [55.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libswscale-dev amd64 7:3.4.11-0ubuntu0.1 [167 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libswscale4 amd64 7:3.4.11-0ubuntu0.1 [150 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavresample-dev amd64 7:3.4.11-0ubuntu0.1 [62.1 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavresample3 amd64 7:3.4.11-0ubuntu0.1 [52.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavutil-dev amd64 7:3.4.11-0ubuntu0.1 [295 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavutil55 amd64 7:3.4.11-0ubuntu0.1 [191 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavformat57 amd64 7:3.4.11-0ubuntu0.1 [953 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavcodec57 amd64 7:3.4.11-0ubuntu0.1 [4,600 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libpostproc54 amd64 7:3.4.11-0ubuntu0.1 [50.3 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavfilter6 amd64 7:3.4.11-0ubuntu0.1 [875 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavdevice57 amd64 7:3.4.11-0ubuntu0.1 [75.1 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 ffmpeg amd64 7:3.4.11-0ubuntu0.1 [1,587 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.10 [784 kB]\n",
            "Fetched 16.2 MB in 4s (4,577 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 17.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 155632 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libavformat-dev_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavformat-dev:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../01-libavcodec-dev_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavcodec-dev:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../02-libswresample-dev_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libswresample-dev:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../03-libswresample2_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libswresample2:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../04-libswscale-dev_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libswscale-dev:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../05-libswscale4_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libswscale4:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../06-libavresample-dev_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavresample-dev:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../07-libavresample3_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavresample3:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../08-libavutil-dev_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavutil-dev:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../09-libavutil55_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavutil55:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../10-libavformat57_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavformat57:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../11-libavcodec57_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavcodec57:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../12-libpostproc54_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpostproc54:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../13-libavfilter6_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavfilter6:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../14-libavdevice57_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavdevice57:amd64 (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Preparing to unpack .../15-ffmpeg_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking ffmpeg (7:3.4.11-0ubuntu0.1) over (7:3.4.8-0ubuntu0.2) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../16-xvfb_2%3a1.19.6-1ubuntu4.10_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up libavutil55:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up libswresample2:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libswscale4:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libpostproc54:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libavutil-dev:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libavresample3:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libavcodec57:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libavresample-dev:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libswscale-dev:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libswresample-dev:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libavformat57:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libavfilter6:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libavcodec-dev:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libavformat-dev:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up libavdevice57:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
            "Setting up ffmpeg (7:3.4.11-0ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio==2.4.0\n",
            "  Downloading imageio-2.4.0.tar.gz (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (7.1.2)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.0-py3-none-any.whl size=3303895 sha256=236948a8b6fffaeca8011e29c901511cc389497e8fd977b2947b90a1094047d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/de/2f/6c5a75120d68a2c3138120c8d0ce1c6f9483a4b96307986bf2\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed imageio-2.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf-agents[reverb]\n",
            "  Downloading tf_agents-0.13.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.1.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.3.0)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.17.3)\n",
            "Requirement already satisfied: tensorflow-probability>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.16.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.15.0)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 26.3 MB/s \n",
            "\u001b[?25hCollecting rlds\n",
            "  Downloading rlds-0.1.4-py3-none-manylinux2010_x86_64.whl (37 kB)\n",
            "Collecting tensorflow~=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 4.3 kB/s \n",
            "\u001b[?25hCollecting dm-reverb~=0.8.0\n",
            "  Downloading dm_reverb-0.8.0-cp37-cp37m-manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 24.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm-reverb~=0.8.0->tf-agents[reverb]) (0.1.7)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.7/dist-packages (from dm-reverb~=0.8.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.16.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (1.6.3)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (57.4.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 32.9 MB/s \n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 82.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (21.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (14.0.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (1.1.2)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (0.26.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (1.46.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-agents[reverb]) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (3.3.7)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (3.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.16.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow~=2.9.0->tf-agents[reverb]) (3.0.9)\n",
            "Installing collected packages: gast, tensorflow-estimator, tensorboard, pygame, keras, flatbuffers, tf-agents, tensorflow, rlds, dm-reverb\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "Successfully installed dm-reverb-0.8.0 flatbuffers-1.12 gast-0.4.0 keras-2.9.0 pygame-2.1.0 rlds-0.1.4 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tf-agents-0.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install QuantLib\n",
        "!pip install -q tf-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4UoCkG_Ofvv",
        "outputId": "ce27e8e3-446f-4b60-df7a-5e529cf8d558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting QuantLib\n",
            "  Downloading QuantLib-1.26-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (17.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.8 MB 3.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: QuantLib\n",
            "Successfully installed QuantLib-1.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **No Abandon**"
      ],
      "metadata": {
        "id": "NtyIa7vLn2al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tf_agents.policies import policy_saver\n",
        "import tempfile\n",
        "import random\n",
        "import os\n",
        "from tf_agents.utils import common  # loss function\n",
        "from tf_agents.trajectories import trajectory  # s->s' trajectory\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer  # replay buffer\n",
        "from tf_agents.networks import q_network  # Q net\n",
        "from tf_agents.environments import tf_py_environment  # gym to tf gym\n",
        "from tf_agents.environments import gym_wrapper  # wrap OpenAI gym\n",
        "from tf_agents.agents.ddpg import ddpg_agent  # DDPG Agent, also some other agents, discussed later\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gym\n",
        "import QuantLib as ql  # used for calculating the price of option if we hold it, baseline\n",
        "\n",
        "# Build and Abandon Gym Environment\n",
        "class BuildAbandonOptionEnv(gym.Env): #put\n",
        "    def __init__(self):\n",
        "        self.S0 = 100.0\n",
        "        self.K = 5.0\n",
        "        self.r = 0.03\n",
        "        self.sigma = 0.10\n",
        "        self.T = 2.0\n",
        "        self.tc = 0.5\n",
        "        self.gamma = 1.0\n",
        "        self.Cop = 100.0\n",
        "        self.Cab = 1.0\n",
        "        self.tb = 0 # this is our state to observe\n",
        "        self.N = 500    # 500 day, only do 20 days first\n",
        "\n",
        "        # 1. at time step t, my abandon happens when E(V_t) < 0, with the abandon and cost\n",
        "        # 2. 4 states: S, t, ta, tb \n",
        "        # 2. we don't have a aboundary for building and abandoning (t > t_b + t_c)\n",
        "        # 3. Traning Algorithm: States: 1. S, 2. ta, 3. tb\n",
        "\n",
        "        self.build = False\n",
        "        self.EV_keep = 0\n",
        "        self.fb = 100\n",
        "\n",
        "        self.S1 = 0\n",
        "        self.reward = 0\n",
        "        self.current_day = 0    # from day 0 taking N steps to day N\n",
        "        self.underlying_prices = []\n",
        "        self.time = []\n",
        "        self.integral = []\n",
        "        self.integral_sum = 0\n",
        "        self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "        self.action_space = gym.spaces.Box(low=100, high=105, shape=(1,))    \n",
        "        self.observation_space = gym.spaces.Box(low=np.array([0, 0, 0]), high=np.array(\n",
        "            [np.inf, 2.0, 2.0]), dtype=np.float32)      # S in [0, inf], tao in [0, 1]\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.build == False and self.S1 >= action:   \n",
        "            self.build = True\n",
        "            self.tb = self.current_day_ratio\n",
        "            if self.current_day_ratio == self.T:\n",
        "              reward = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.current_day_ratio)))\n",
        "              done = True\n",
        "            else:\n",
        "              reward = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.current_day_ratio)))\n",
        "              self.current_day += 1\n",
        "              self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "              self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "              self.underlying_prices.append(self.S1)\n",
        "              self.time.append(self.current_day_ratio)\n",
        "              self.integral.append(np.exp(-self.r * self.time[-1])*self.gamma*(self.underlying_prices[-1]-self.Cop))\n",
        "              done = False\n",
        "            # print(\"If 2\")\n",
        "            self.fb = action\n",
        "        elif self.build == True:\n",
        "            if (self.current_day_ratio >= self.tb) and (self.current_day_ratio < (self.tb + self.tc)):\n",
        "                if self.current_day_ratio == self.T:\n",
        "                    reward = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.current_day_ratio)))\n",
        "                    done = True\n",
        "                else:\n",
        "                    reward = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.current_day_ratio)))\n",
        "                    self.current_day += 1\n",
        "                    self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "                    self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "                    self.underlying_prices.append(self.S1)\n",
        "                    self.time.append(self.current_day_ratio)\n",
        "                    self.integral.append(np.exp(-self.r * self.time[-1])*self.gamma*(self.underlying_prices[-1]-self.Cop))\n",
        "                    done = False\n",
        "            elif (self.current_day_ratio >= (self.tb + self.tc)):\n",
        "                  self.integral_sum = sum(self.integral)\n",
        "                  self.EV_keep = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.current_day_ratio))) + self.integral_sum\n",
        "                  if self.current_day_ratio == self.T:\n",
        "                      reward = self.EV_keep\n",
        "                      done = True\n",
        "                  else:\n",
        "                      reward = self.EV_keep\n",
        "                      self.current_day += 1\n",
        "                      self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "                      self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "                      self.underlying_prices.append(self.S1)\n",
        "                      self.time.append(self.current_day_ratio)\n",
        "                      self.integral.append(np.exp(-self.r * self.time[-1])*self.gamma*(self.underlying_prices[-1]-self.Cop))\n",
        "                      done = False\n",
        "        elif self.build == False and self.S1 < action:   \n",
        "            if self.current_day_ratio == self.T:\n",
        "              reward = 0\n",
        "              done = True\n",
        "            else:\n",
        "              reward = 0\n",
        "              self.current_day += 1\n",
        "              self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "              self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "              self.underlying_prices.append(self.S1)\n",
        "              self.time.append(self.current_day_ratio)\n",
        "              self.integral.append(np.exp(-self.r * self.time[-1])*self.gamma*(self.underlying_prices[-1]-self.Cop))\n",
        "              done = False\n",
        "        # print(action)\n",
        "        return np.array([self.S1, self.current_day_ratio, self.tb]), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.build = False\n",
        "        self.tb = 0\n",
        "        self.current_day = self.tb*(self.N/self.T)\n",
        "        self.S1 = self.S0\n",
        "        self.underlying_prices = [0]\n",
        "        self.time = [0]\n",
        "        self.integral = [0]\n",
        "        self.integral_sum = 0\n",
        "        self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "        self.EV_keep = 0\n",
        "        self.fb = 100\n",
        "        return [self.S1, self.current_day_ratio, self.tb]"
      ],
      "metadata": {
        "id": "zDp6l484n1vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tf_agents.agents.ddpg import ddpg_agent\n",
        "from tf_agents.agents.ddpg import actor_network\n",
        "from tf_agents.agents.ddpg import critic_network\n",
        "# Hyper-parameters\n",
        "num_iterations = 20000  # @param {type:\"integer\"}\n",
        "\n",
        "collect_steps_per_iteration = 10  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 2000\n",
        "\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "train_env_gym = BuildAbandonOptionEnv() # american put env\n",
        "eval_env_gym = BuildAbandonOptionEnv() # test case\n",
        "\n",
        "train_env_wrap = gym_wrapper.GymWrapper(train_env_gym)\n",
        "eval_env_wrap = gym_wrapper.GymWrapper(eval_env_gym)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_env_wrap)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_env_wrap)\n",
        "\n",
        "\n",
        "actor_optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "critic_optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "act_net = actor_network.ActorNetwork(input_tensor_spec = train_env.observation_spec(),\n",
        "                                     output_tensor_spec = train_env.action_spec(),\n",
        "                                     fc_layer_params = (100,),\n",
        "                                     activation_fn = tf.keras.activations.relu                 \n",
        "                                     )\n",
        "\n",
        "crit_net = critic_network.CriticNetwork(input_tensor_spec = (train_env.observation_spec(), train_env.action_spec()),\n",
        "                                        observation_fc_layer_params = (100,),\n",
        "                                        action_fc_layer_params = None,\n",
        "                                        joint_fc_layer_params = (100,),\n",
        "                                        activation_fn = tf.keras.activations.relu\n",
        "                                        )\n",
        "starter_epsilon = 1.0\n",
        "end_epsilon = 0.5\n",
        "decay_steps = num_iterations + initial_collect_steps\n",
        "ou_noise_size = tf.compat.v1.train.polynomial_decay(starter_epsilon,\n",
        "                                                    train_step_counter,\n",
        "                                                    decay_steps,\n",
        "                                                    end_epsilon,\n",
        "                                                    power=1.0,\n",
        "                                                    cycle=False)\n",
        "agent = ddpg_agent.DdpgAgent(time_step_spec = train_env.time_step_spec(),\n",
        "                             action_spec = train_env.action_spec(),\n",
        "                             actor_network = act_net,\n",
        "                             critic_network = crit_net,\n",
        "                             actor_optimizer = actor_optimizer,\n",
        "                             critic_optimizer = critic_optimizer, \n",
        "                             gamma = 0.99,\n",
        "                             target_critic_network = None, # Target network = same as primary\n",
        "                             target_update_tau = 0.1, \n",
        "                             ou_stddev = ou_noise_size(), # was 1 \n",
        "                             ou_damping = 0.25,\n",
        "                             td_errors_loss_fn = common.element_wise_squared_loss,\n",
        "                             train_step_counter=train_step_counter\n",
        "                             )\n",
        "agent.initialize()\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)\n",
        "\n",
        "# the buffer will update the Q table based on not only the past one step, but some older steps as well.\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# eval_env evaluation\n",
        "\n",
        "# computer average return of the Q network, which in our case is the reward, which is premium option price\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "    total_return = 0.0\n",
        "    for i in range(num_episodes):\n",
        "\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "        \n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "# Data Collection\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "    # Add trajectory to the replay buffer\n",
        "    buffer.add_batch(traj)\n",
        "\n",
        "# common loop in RL- especailly DQN\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "    for i in range(steps):\n",
        "        collect_step(env, policy, buffer)\n",
        "\n",
        "# training!!\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "    for j in range(collect_steps_per_iteration):\n",
        "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('step = {0}: loss = {1}, noise = {2}'.format(step, train_loss, float(np.round(np.array(ou_noise_size()),2))))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        avg_return = compute_avg_return(\n",
        "            eval_env, agent.policy, num_eval_episodes)\n",
        "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "        returns.append(avg_return)\n",
        "\n",
        "# plot training iterations\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=2)\n",
        "\n",
        "# save policy\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "tf_policy_saver.save(policy_dir)\n",
        "\n",
        "saved_policy = tf.compat.v2.saved_model.load(policy_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "EHJAFbeNtnZE",
        "outputId": "c3ecf64e-ef20-4ad2-e5fe-04d02ae305a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 8204998.0, noise = 1.0\n",
            "step = 400: loss = 5137481.0, noise = 0.9900000095367432\n",
            "step = 600: loss = 4025779.0, noise = 0.9900000095367432\n",
            "step = 800: loss = 3433072.75, noise = 0.9800000190734863\n",
            "step = 1000: loss = 3996287.25, noise = 0.9800000190734863\n",
            "step = 1000: Average Return = -111881.75\n",
            "step = 1200: loss = 4083610.25, noise = 0.9700000286102295\n",
            "step = 1400: loss = 5037939.0, noise = 0.9700000286102295\n",
            "step = 1600: loss = 4569550.0, noise = 0.9599999785423279\n",
            "step = 1800: loss = 3274204.5, noise = 0.9599999785423279\n",
            "step = 2000: loss = 4157018.25, noise = 0.949999988079071\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d9f21f406b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         avg_return = compute_avg_return(\n\u001b[0;32m--> 146\u001b[0;31m             eval_env, agent.policy, num_eval_episodes)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step = {0}: Average Return = {1}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_return\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mreturns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_return\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-d9f21f406b4a>\u001b[0m in \u001b[0;36mcompute_avg_return\u001b[0;34m(environment, policy, num_episodes)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0maction_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mtime_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mepisode_return\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/policies/tf_policy.py\u001b[0m in \u001b[0;36maction\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_automatic_state_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m       \u001b[0mpolicy_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_reset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclip_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/utils/common.py\u001b[0m in \u001b[0;36mwith_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# autodep-like behavior is already expected of fn.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresource_variables_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMISSING_RESOURCE_VARIABLES_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/policies/tf_policy.py\u001b[0m in \u001b[0;36m_action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \"\"\"\n\u001b[1;32m    559\u001b[0m     \u001b[0mseed_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeedStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msalt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf_agents_tf_policy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     \u001b[0mdistribution_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=wrong-arg-types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m     actions = tf.nest.map_structure(\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreparameterized_sampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/policies/actor_policy.py\u001b[0m in \u001b[0;36m_distribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    180\u001b[0m     actions_or_distributions, policy_state = self._apply_actor_network(\n\u001b[1;32m    181\u001b[0m         \u001b[0mnetwork_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         policy_state=policy_state, mask=mask)\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_to_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_or_distribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/policies/actor_policy.py\u001b[0m in \u001b[0;36m_apply_actor_network\u001b[0;34m(self, observation, step_type, policy_state, mask)\u001b[0m\n\u001b[1;32m    152\u001b[0m       return self._actor_network(\n\u001b[1;32m    153\u001b[0m           \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m           training=self._training)\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m       return self._actor_network(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/networks/network.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_network_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \"\"\"\n\u001b[0;32m--> 390\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_tensor_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m       nest_utils.assert_matching_dtypes_and_inner_shapes(\n\u001b[1;32m    392\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/networks/network.py\u001b[0m in \u001b[0;36minput_tensor_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minput_tensor_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;34m\"\"\"Returns the spec of the input to the network of type InputSpec.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_tensor_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcreate_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Old Build and Abandon**"
      ],
      "metadata": {
        "id": "QuSoMBuun6TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tf_agents.policies import policy_saver\n",
        "import tempfile\n",
        "import random\n",
        "import os\n",
        "from tf_agents.utils import common  # loss function\n",
        "from tf_agents.trajectories import trajectory  # s->s' trajectory\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer  # replay buffer\n",
        "from tf_agents.networks import q_network  # Q net\n",
        "from tf_agents.environments import tf_py_environment  # gym to tf gym\n",
        "from tf_agents.environments import gym_wrapper  # wrap OpenAI gym\n",
        "from tf_agents.agents.dqn import dqn_agent  # DQN Agent, also some other agents, discussed later\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gym\n",
        "import QuantLib as ql  # used for calculating the price of option if we hold it, baseline\n",
        "\n",
        "# Build and Abandon Gym Environment\n",
        "class BuildAbandonOptionEnv(gym.Env): #put\n",
        "    def __init__(self):\n",
        "        self.S0 = 100.0\n",
        "        self.K = 5.0\n",
        "        self.r = 0.03\n",
        "        self.sigma = 0.10\n",
        "        self.T = 2.0\n",
        "        self.tc = 0.5\n",
        "        self.gamma = 1.0\n",
        "        self.Cop = 100.0\n",
        "        self.Cab = 1.0\n",
        "        self.ta = 2.0 # this is our state to observe\n",
        "        self.tb = 0 # this is our state to observe\n",
        "        self.N = 500    # 500 day, only do 20 days first\n",
        "\n",
        "        # 1. at time step t, my abandon happens when E(V_t) < 0, with the abandon and cost\n",
        "        # 2. 4 states: S, t, ta, tb \n",
        "        # 2. we don't have a aboundary for building and abandoning (t > t_b + t_c)\n",
        "        # 3. Traning Algorithm: States: 1. S, 2. ta, 3. tb\n",
        "\n",
        "        self.build = False\n",
        "        self.abandon = False\n",
        "        self.EV_abandon = 0\n",
        "        self.EV_keep = 0\n",
        "        self.fb = 100\n",
        "        self.fa = 100\n",
        "        self.panelty = 1.0\n",
        "\n",
        "        self.S1 = 0\n",
        "        self.reward = 0\n",
        "        self.current_day = 0    # from day 0 taking N steps to day N\n",
        "        self.underlying_prices = []\n",
        "        self.time = []\n",
        "        self.integral = []\n",
        "        self.integral_sum = 0\n",
        "        self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "\n",
        "        self.action_space = gym.spaces.Discrete(2)        \n",
        "        self.observation_space = gym.spaces.Box(low=np.array([0, 0, 0]), high=np.array(\n",
        "            [np.inf, 2.0, 2.0]), dtype=np.float32)      # S in [0, inf], tao in [0, 1]\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.build == False and self.abandon == False:   # at time t <= tb, no build yet\n",
        "          if action == 0:\n",
        "            if self.current_day_ratio == self.T:\n",
        "              reward = 0\n",
        "              done = True\n",
        "            else:\n",
        "              reward = 0\n",
        "              self.current_day += 1\n",
        "              self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "              self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "              self.underlying_prices.append(self.S1)\n",
        "              self.time.append(self.current_day_ratio)\n",
        "              done = False\n",
        "          elif action == 1: # we just build it now\n",
        "            self.fb = self.S1\n",
        "            if self.current_day_ratio == self.T:\n",
        "                self.tb = self.T\n",
        "                self.build = True\n",
        "                reward = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.current_day_ratio)))\n",
        "                done = True\n",
        "            else:\n",
        "                self.tb = self.current_day_ratio\n",
        "                self.build = True\n",
        "                reward = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.current_day_ratio)))\n",
        "                self.current_day += 1\n",
        "                self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "                self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "                self.underlying_prices.append(self.S1)\n",
        "                self.time.append(self.current_day_ratio)\n",
        "                done = False\n",
        "        elif self.build == True and self.abandon == False: # we have built the plant, and we haven't abandon it yet, plus we don't want to abandon it right now\n",
        "          self.EV_abandon = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.current_day_ratio)))  \n",
        "          self.EV_keep = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.current_day_ratio))) \n",
        "          if action == 0:\n",
        "            if (self.current_day_ratio >= self.tb) and (self.current_day_ratio < (self.tb + self.tc)):\n",
        "                if self.current_day_ratio == self.T:\n",
        "                    reward = self.EV_keep\n",
        "                    done = True\n",
        "                else:\n",
        "                    reward = self.EV_keep\n",
        "                    self.current_day += 1\n",
        "                    self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "                    self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "                    self.underlying_prices.append(self.S1)\n",
        "                    self.time.append(self.current_day_ratio)\n",
        "                    done = False\n",
        "            elif (self.current_day_ratio >= (self.tb + self.tc)) and (self.current_day_ratio < self.ta):\n",
        "                self.integral_sum = sum(self.integral)\n",
        "                self.EV_keep = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.current_day_ratio))) + self.integral_sum\n",
        "                if self.EV_keep >= self.EV_abandon:\n",
        "                  if self.current_day_ratio == self.T:\n",
        "                      reward = self.EV_keep\n",
        "                      done = True\n",
        "                  else:\n",
        "                      reward = self.EV_keep\n",
        "                      self.current_day += 1\n",
        "                      self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "                      self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "                      self.underlying_prices.append(self.S1)\n",
        "                      self.time.append(self.current_day_ratio)\n",
        "                      self.integral.append((self.T/self.N)*np.exp(-self.r * self.time[-1])*self.gamma*(self.underlying_prices[-1]-self.Cop))\n",
        "                      done = False\n",
        "                elif self.EV_keep < self.EV_abandon:\n",
        "                  if self.current_day_ratio == self.T:\n",
        "                      reward = self.EV_keep - self.panelty*abs(self.EV_abandon - self.EV_keep)\n",
        "                      done = True\n",
        "                  else:\n",
        "                      reward = self.EV_keep - self.panelty*abs(self.EV_abandon - self.EV_keep)\n",
        "                      self.current_day += 1\n",
        "                      self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "                      self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "                      self.underlying_prices.append(self.S1)\n",
        "                      self.time.append(self.current_day_ratio)\n",
        "                      self.integral.append((self.T/self.N)*np.exp(-self.r * self.time[-1])*self.gamma*(self.underlying_prices[-1]-self.Cop))\n",
        "                      done = False\n",
        "          elif action == 1:\n",
        "            self.fa = self.S1\n",
        "            if (self.current_day_ratio >= self.tb) and (self.current_day_ratio < (self.tb + self.tc)):\n",
        "              self.ta = self.current_day_ratio\n",
        "              self.abandon = True\n",
        "              if self.current_day_ratio == self.T:\n",
        "                    reward = self.EV_abandon\n",
        "                    done = True\n",
        "              else:\n",
        "                    reward = self.EV_abandon\n",
        "                    self.current_day += 1\n",
        "                    self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "                    self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "                    self.underlying_prices.append(self.S1)\n",
        "                    self.time.append(self.current_day_ratio)\n",
        "                    self.integral.append((self.T/self.N)*np.exp(-self.r * self.time[-1])*self.gamma*(self.underlying_prices[-1]-self.Cop))\n",
        "                    done = False\n",
        "            elif (self.current_day_ratio >= (self.tb + self.tc)) and (self.current_day_ratio < self.ta):\n",
        "                self.ta = self.current_day_ratio\n",
        "                self.abandon = True\n",
        "                self.integral_sum = sum(self.integral)\n",
        "                self.EV_keep = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.current_day_ratio))) + self.integral_sum\n",
        "                if self.EV_keep > self.EV_abandon:\n",
        "                  if self.current_day_ratio == self.T:\n",
        "                      reward = self.EV_abandon - abs(self.EV_keep - self.EV_abandon)\n",
        "                      done = True\n",
        "                  else:\n",
        "                      reward = self.EV_abandon - abs(self.EV_keep - self.EV_abandon)\n",
        "                      self.current_day += 1\n",
        "                      self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "                      self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "                      self.underlying_prices.append(self.S1)\n",
        "                      self.time.append(self.current_day_ratio)\n",
        "                      self.integral.append((self.T/self.N)*np.exp(-self.r * self.time[-1])*self.gamma*(self.underlying_prices[-1]-self.Cop))\n",
        "                      done = False\n",
        "                elif self.EV_keep <= self.EV_abandon:\n",
        "                  if self.current_day_ratio == self.T:\n",
        "                      reward = self.EV_abandon\n",
        "                      done = True\n",
        "                  else:\n",
        "                      reward = self.EV_abandon\n",
        "                      self.current_day += 1\n",
        "                      self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "                      self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "                      self.underlying_prices.append(self.S1)\n",
        "                      self.time.append(self.current_day_ratio)\n",
        "                      self.integral.append((self.T/self.N)*np.exp(-self.r * self.time[-1])*self.gamma*(self.underlying_prices[-1]-self.Cop))\n",
        "                      done = False\n",
        "        elif self.build == True and self.abandon == True:\n",
        "            if (self.current_day_ratio >= self.ta):\n",
        "                if self.current_day_ratio == self.T:\n",
        "                    reward = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.ta)))\n",
        "                    done = True\n",
        "                else:\n",
        "                    reward = -(self.K * np.exp(-self.r * self.tb) + (self.Cab * np.exp(-self.r * self.ta)))\n",
        "                    self.current_day += 1\n",
        "                    self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "                    self.S1 = self.S1 * np.exp((self.r - 0.5 * self.sigma**2) * (self.T/self.N) + self.sigma * np.sqrt(self.T/self.N) * np.random.normal()) #GBM process price\n",
        "                    self.underlying_prices.append(self.S1)\n",
        "                    self.time.append(self.current_day_ratio)\n",
        "                    self.integral.append((self.T/self.N)*np.exp(-self.r * self.time[-1])*self.gamma*(self.underlying_prices[-1]-self.Cop))\n",
        "                    done = False\n",
        "        return np.array([self.S1,self.tb, self.ta]), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.build = False\n",
        "        self.abandon = False\n",
        "        self.tb = 0\n",
        "        self.ta = 2.0\n",
        "        self.current_day = self.tb*(self.N/self.T)\n",
        "        self.S1 = self.S0\n",
        "        self.underlying_prices = [0]\n",
        "        self.time = [0]\n",
        "        self.integral = [0]\n",
        "        self.integral_sum = 0\n",
        "        self.current_day_ratio = self.current_day/(self.N/self.T)\n",
        "        self.EV_abandon = 0\n",
        "        self.EV_keep = 0\n",
        "        self.fb = 100\n",
        "        self.fa = 100\n",
        "        return [self.S1, self.tb, self.ta]"
      ],
      "metadata": {
        "id": "5sfucY21aiRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "num_iterations = 20000  # @param {type:\"integer\"}\n",
        "\n",
        "collect_steps_per_iteration = 10  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "train_env_gym = BuildAbandonOptionEnv() # american put env\n",
        "eval_env_gym = BuildAbandonOptionEnv() # test case\n",
        "\n",
        "train_env_wrap = gym_wrapper.GymWrapper(train_env_gym)\n",
        "eval_env_wrap = gym_wrapper.GymWrapper(eval_env_gym)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_env_wrap)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_env_wrap)\n",
        "\n",
        "fc_layer_params = (200,) # number of hidden layers\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DdqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)\n",
        "\n",
        "# the buffer will update the Q table based on not only the past one step, but some older steps as well.\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# eval_env evaluation\n",
        "\n",
        "# computer average return of the Q network, which in our case is the reward, which is premium option price\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "    total_return = 0.0\n",
        "    for i in range(num_episodes):\n",
        "\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "\n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "# Data Collection\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "    # Add trajectory to the replay buffer\n",
        "    buffer.add_batch(traj)\n",
        "\n",
        "# common loop in RL- especailly DQN\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "    for i in range(steps):\n",
        "        collect_step(env, policy, buffer)\n",
        "\n",
        "# training!!\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "    for j in range(collect_steps_per_iteration):\n",
        "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        avg_return = compute_avg_return(\n",
        "            eval_env, agent.policy, num_eval_episodes)\n",
        "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "        returns.append(avg_return)\n",
        "\n",
        "# plot training iterations\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=2)\n",
        "\n",
        "# save policy\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "tf_policy_saver.save(policy_dir)\n",
        "\n",
        "saved_policy = tf.compat.v2.saved_model.load(policy_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTanW3Kq8DBC",
        "outputId": "cb38d912-fd5f-47c9-8821-0f4ecde2c6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 6613.47314453125\n",
            "step = 400: loss = 100.58078002929688\n",
            "step = 600: loss = 14916.6298828125\n",
            "step = 800: loss = 107.72962951660156\n",
            "step = 1000: loss = 141.1700439453125\n",
            "step = 1000: Average Return = 0.0\n",
            "step = 1200: loss = 134.8883514404297\n",
            "step = 1400: loss = 162.22027587890625\n",
            "step = 1600: loss = 109.32025146484375\n",
            "step = 1800: loss = 10458.90625\n",
            "step = 2000: loss = 15749.1474609375\n",
            "step = 2000: Average Return = 0.0\n",
            "step = 2200: loss = 120.163330078125\n",
            "step = 2400: loss = 28016.47265625\n",
            "step = 2600: loss = 89.25239562988281\n",
            "step = 2800: loss = 9014.875\n",
            "step = 3000: loss = 10343.2548828125\n",
            "step = 3000: Average Return = 0.0\n",
            "step = 3200: loss = 69.64776611328125\n",
            "step = 3400: loss = 130.6139678955078\n",
            "step = 3600: loss = 159.30230712890625\n",
            "step = 3800: loss = 117.51951599121094\n",
            "step = 4000: loss = 10169.7197265625\n",
            "step = 4000: Average Return = 0.0\n",
            "step = 4200: loss = 146.42454528808594\n",
            "step = 4400: loss = 103.6318130493164\n",
            "step = 4600: loss = 106.20716857910156\n",
            "step = 4800: loss = 5741.89306640625\n",
            "step = 5000: loss = 7289.94140625\n",
            "step = 5000: Average Return = -3005.958740234375\n",
            "step = 5200: loss = 114.36473083496094\n",
            "step = 5400: loss = 124.20196533203125\n",
            "step = 5600: loss = 94.50746154785156\n",
            "step = 5800: loss = 91.05680084228516\n",
            "step = 6000: loss = 12550.384765625\n",
            "step = 6000: Average Return = -3005.958740234375\n",
            "step = 6200: loss = 101.67091369628906\n",
            "step = 6400: loss = 132.76553344726562\n",
            "step = 6600: loss = 91.81224822998047\n",
            "step = 6800: loss = 124.46087646484375\n",
            "step = 7000: loss = 138.31112670898438\n",
            "step = 7000: Average Return = -3005.958740234375\n",
            "step = 7200: loss = 125.15751647949219\n",
            "step = 7400: loss = 85.42462921142578\n",
            "step = 7600: loss = 23603.46484375\n",
            "step = 7800: loss = 96.22195434570312\n",
            "step = 8000: loss = 6212.73876953125\n",
            "step = 8000: Average Return = -3005.958740234375\n",
            "step = 8200: loss = 15000.8251953125\n",
            "step = 8400: loss = 85.53541564941406\n",
            "step = 8600: loss = 120.1387939453125\n",
            "step = 8800: loss = 119.03538513183594\n",
            "step = 9000: loss = 107.75981140136719\n",
            "step = 9000: Average Return = 0.0\n",
            "step = 9200: loss = 7333.45556640625\n",
            "step = 9400: loss = 152.48248291015625\n",
            "step = 9600: loss = 9691.1884765625\n",
            "step = 9800: loss = 8806.1845703125\n",
            "step = 10000: loss = 97.67683410644531\n",
            "step = 10000: Average Return = -3005.958740234375\n",
            "step = 10200: loss = 20551.927734375\n",
            "step = 10400: loss = 117.099365234375\n",
            "step = 10600: loss = 147.95733642578125\n",
            "step = 10800: loss = 106.959228515625\n",
            "step = 11000: loss = 8161.88427734375\n",
            "step = 11000: Average Return = -3005.958740234375\n",
            "step = 11200: loss = 108.67375946044922\n",
            "step = 11400: loss = 14384.0791015625\n",
            "step = 11600: loss = 8404.2724609375\n",
            "step = 11800: loss = 8115.83984375\n",
            "step = 12000: loss = 123.5966796875\n",
            "step = 12000: Average Return = 0.0\n",
            "step = 12200: loss = 6842.20263671875\n",
            "step = 12400: loss = 7352.736328125\n",
            "step = 12600: loss = 18871.9296875\n",
            "step = 12800: loss = 95.3143539428711\n",
            "step = 13000: loss = 7060.08935546875\n",
            "step = 13000: Average Return = 0.0\n",
            "step = 13200: loss = 10734.546875\n",
            "step = 13400: loss = 108.50358581542969\n",
            "step = 13600: loss = 93.13976287841797\n",
            "step = 13800: loss = 105.36288452148438\n",
            "step = 14000: loss = 143.1416015625\n",
            "step = 14000: Average Return = -3005.958740234375\n",
            "step = 14200: loss = 158.908203125\n",
            "step = 14400: loss = 111.76054382324219\n",
            "step = 14600: loss = 116.60975646972656\n",
            "step = 14800: loss = 100.40203857421875\n",
            "step = 15000: loss = 11593.685546875\n",
            "step = 15000: Average Return = -3005.958740234375\n",
            "step = 15200: loss = 124.15229034423828\n",
            "step = 15400: loss = 114.58051300048828\n",
            "step = 15600: loss = 93.8123779296875\n",
            "step = 15800: loss = 115.06317138671875\n",
            "step = 16000: loss = 114.53355407714844\n",
            "step = 16000: Average Return = 0.0\n",
            "step = 16200: loss = 9278.478515625\n",
            "step = 16400: loss = 113.6045913696289\n",
            "step = 16600: loss = 101.27369689941406\n",
            "step = 16800: loss = 8655.537109375\n",
            "step = 17000: loss = 123.35102844238281\n",
            "step = 17000: Average Return = 0.0\n",
            "step = 17200: loss = 13290.55859375\n",
            "step = 17400: loss = 161.71771240234375\n",
            "step = 17600: loss = 137.45339965820312\n",
            "step = 17800: loss = 11164.6162109375\n",
            "step = 18000: loss = 92.85015869140625\n",
            "step = 18000: Average Return = 0.0\n",
            "step = 18200: loss = 11359.0244140625\n",
            "step = 18400: loss = 116.640625\n",
            "step = 18600: loss = 12391.224609375\n",
            "step = 18800: loss = 129.83981323242188\n",
            "step = 19000: loss = 113.07086181640625\n",
            "step = 19000: Average Return = 0.0\n",
            "step = 19200: loss = 105.32646942138672\n",
            "step = 19400: loss = 16643.83203125\n",
            "step = 19600: loss = 9276.1630859375\n",
            "step = 19800: loss = 164.0799560546875\n",
            "step = 20000: loss = 153.41281127929688\n",
            "step = 20000: Average Return = 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as QNetwork_layer_call_fn, QNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses, dense_21_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:524: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /tmp/policy/assets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pricing_dict = {}\n",
        "npv = compute_avg_return(eval_env, agent.policy, num_episodes=100) # not averaged\n",
        "pricing_dict['RL-DQN - 10000 Path'] = npv\n",
        "pricing_dict"
      ],
      "metadata": {
        "id": "ZY1x-4e9YQ5P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "e2775755-8831-47f8-dac8-554d3fadbfd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-486c8623c94f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpricing_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnpv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_avg_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# not averaged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpricing_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RL-DQN - 10000 Path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnpv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpricing_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-b4de4c646592>\u001b[0m in \u001b[0;36mcompute_avg_return\u001b[0;34m(environment, policy, num_episodes)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0maction_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mtime_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mepisode_return\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mtotal_return\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mepisode_return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/environments/tf_environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobservation_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \"\"\"\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/environments/tf_py_environment.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    317\u001b[0m           \u001b[0mflat_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_time_step_dtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m           name='step_py_func')\n\u001b[0m\u001b[1;32m    320\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_time_step_from_numpy_function_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/environments/tf_py_environment.py\u001b[0m in \u001b[0;36m_isolated_step_py\u001b[0;34m(*flattened_actions)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_isolated_step_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflattened_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_step_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflattened_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/environments/tf_py_environment.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/environments/tf_py_environment.py\u001b[0m in \u001b[0;36m_step_py\u001b[0;34m(*flattened_actions)\u001b[0m\n\u001b[1;32m    296\u001b[0m         packed = tf.nest.pack_sequence_as(\n\u001b[1;32m    297\u001b[0m             structure=self.action_spec(), flat_sequence=flattened_actions)\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_time_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_time_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/environments/py_environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    230\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_time_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/environments/batched_py_environment.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_envs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch_nested_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m       \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_envs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_nested_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/environments/py_environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    230\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_time_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/environments/gym_wrapper.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;31m# TODO(oars): Figure out how tuple or dict actions will be generated by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m# agents and if we can pass them through directly to gym.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gym_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_obs_space_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-db22091c4a92>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0maction_build\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0maction_abandon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_build\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_abandon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
          ]
        }
      ]
    }
  ]
}